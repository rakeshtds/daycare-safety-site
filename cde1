-- ============================================
-- Fix for AI_MODEL_USED Column Missing Error
-- ============================================
-- Run this script to add the missing column to your existing CDE_SCAN_RESULTS table

-- Add AI_MODEL_USED column if it doesn't exist
ALTER TABLE CDE_SCAN_RESULTS 
ADD COLUMN AI_MODEL_USED VARCHAR(100);

-- Verify the column was added
DESC TABLE CDE_SCAN_RESULTS;

-- Optional: Update existing records to show they didn't track the model
UPDATE CDE_SCAN_RESULTS 
SET AI_MODEL_USED = 'Not Tracked'
WHERE AI_MODEL_USED IS NULL AND AI_VALIDATED = TRUE;

-- Verify update
SELECT COUNT(*), AI_MODEL_USED 
FROM CDE_SCAN_RESULTS 
GROUP BY AI_MODEL_USED;

SELECT '‚úÖ Column AI_MODEL_USED added successfully!' AS STATUS;

# QUICK FIX GUIDE - CDE App Errors

## Problem 1: AI_MODEL_USED Column Missing ‚ùå
**Error**: `SQL compilation error: invalid identifier 'AI_MODEL_USED'`

## Problem 2: Model Not Authorized ‚ùå  
**Error**: `model doesn't exist or is not authorised`

---

## SOLUTION 1: Add Missing Column (Run This First!)

### Step 1: Execute This SQL in Snowflake

```sql
-- Add the missing AI_MODEL_USED column
ALTER TABLE CDE_SCAN_RESULTS 
ADD COLUMN IF NOT EXISTS AI_MODEL_USED VARCHAR(100);

-- Verify it was added
DESC TABLE CDE_SCAN_RESULTS;

-- You should see AI_MODEL_USED in the list now
SELECT 'Column added successfully!' AS STATUS;
```

### Step 2: Make INSERT Statement Conditional

Find this section in your code (around line 3800-3900 in the scan results saving part):

**BEFORE (Causes Error):**
```python
insert_query = f"""
INSERT INTO CDE_SCAN_RESULTS (
    SCAN_RUN_ID, DATABASE_NAME, SCHEMA_NAME, TABLE_NAME, COLUMN_NAME, DATA_TYPE,
    MATCHED_CDE_ID, MATCHED_DOMAIN, MATCHED_TAG, MATCHED_ATTRIBUTE_LOGICAL_NAME,
    MATCHED_IS_PII, MATCHED_DEFINITION, PATTERN_ID, PATTERN_TYPE, PATTERN_VALUE,
    MATCH_SCORE, MATCH_REASON, MATCH_METHOD, AI_VALIDATED, AI_MODEL_USED
) VALUES (
    ..., '{match['AI_MODEL_USED']}'
)
"""
```

**AFTER (Fixed):**
```python
# Check if AI_MODEL_USED column exists (add this function at the top)
@st.cache_data(ttl=3600)
def has_ai_model_column():
    try:
        desc = session.sql("DESC TABLE CDE_SCAN_RESULTS").to_pandas()
        return 'AI_MODEL_USED' in desc['name'].str.upper().tolist()
    except:
        return False

# Then in your INSERT statement:
has_column = has_ai_model_column()

if has_column:
    # Include AI_MODEL_USED
    insert_query = f"""
    INSERT INTO CDE_SCAN_RESULTS (
        SCAN_RUN_ID, DATABASE_NAME, SCHEMA_NAME, TABLE_NAME, COLUMN_NAME, DATA_TYPE,
        MATCHED_CDE_ID, MATCHED_DOMAIN, MATCHED_TAG, MATCHED_ATTRIBUTE_LOGICAL_NAME,
        MATCHED_IS_PII, MATCHED_DEFINITION, PATTERN_ID, PATTERN_TYPE, PATTERN_VALUE,
        MATCH_SCORE, MATCH_REASON, MATCH_METHOD, AI_VALIDATED, AI_MODEL_USED
    ) VALUES (
        '{match['SCAN_RUN_ID']}', '{match['DATABASE_NAME']}', '{match['SCHEMA_NAME']}',
        '{match['TABLE_NAME']}', '{match['COLUMN_NAME']}', '{match['DATA_TYPE']}',
        {match['MATCHED_CDE_ID']}, '{match['MATCHED_DOMAIN']}', '{match['MATCHED_TAG']}',
        '{match['MATCHED_ATTRIBUTE_LOGICAL_NAME']}', '{match['MATCHED_IS_PII']}', '{def_clean}',
        {match['PATTERN_ID'] if match['PATTERN_ID'] else 'NULL'}, '{match['PATTERN_TYPE']}',
        '{match['PATTERN_VALUE']}', {match['MATCH_SCORE']}, '{reason_clean}',
        '{match['MATCH_METHOD']}', {match['AI_VALIDATED']}, '{match.get('AI_MODEL_USED', 'Unknown')}'
    )
    """
else:
    # Exclude AI_MODEL_USED
    insert_query = f"""
    INSERT INTO CDE_SCAN_RESULTS (
        SCAN_RUN_ID, DATABASE_NAME, SCHEMA_NAME, TABLE_NAME, COLUMN_NAME, DATA_TYPE,
        MATCHED_CDE_ID, MATCHED_DOMAIN, MATCHED_TAG, MATCHED_ATTRIBUTE_LOGICAL_NAME,
        MATCHED_IS_PII, MATCHED_DEFINITION, PATTERN_ID, PATTERN_TYPE, PATTERN_VALUE,
        MATCH_SCORE, MATCH_REASON, MATCH_METHOD, AI_VALIDATED
    ) VALUES (
        '{match['SCAN_RUN_ID']}', '{match['DATABASE_NAME']}', '{match['SCHEMA_NAME']}',
        '{match['TABLE_NAME']}', '{match['COLUMN_NAME']}', '{match['DATA_TYPE']}',
        {match['MATCHED_CDE_ID']}, '{match['MATCHED_DOMAIN']}', '{match['MATCHED_TAG']}',
        '{match['MATCHED_ATTRIBUTE_LOGICAL_NAME']}', '{match['MATCHED_IS_PII']}', '{def_clean}',
        {match['PATTERN_ID'] if match['PATTERN_ID'] else 'NULL'}, '{match['PATTERN_TYPE']}',
        '{match['PATTERN_VALUE']}', {match['MATCH_SCORE']}, '{reason_clean}',
        '{match['MATCH_METHOD']}', {match['AI_VALIDATED']}
    )
    """
```

---

## SOLUTION 2: Fix Model Authorization Issues

### Step 1: Test Which Models Work in Your Account

Add this function to your code:

```python
def test_available_models():
    """Test which Cortex models actually work in your account"""
    
    # Common models to test
    models = [
        'mixtral-8x7b',
        'mistral-large2',
        'mistral-7b',
        'llama3.1-70b',
        'llama3.1-8b',
        'snowflake-arctic',
        'reka-flash',
        'gemma-7b'
    ]
    
    working_models = []
    
    st.write("Testing models in your account...")
    
    for model in models:
        try:
            # Try a simple completion
            test_sql = f"""
            SELECT SNOWFLAKE.CORTEX.COMPLETE(
                '{model}',
                'test'
            ) as response
            """
            result = session.sql(test_sql).collect()
            
            if result:
                working_models.append(model)
                st.success(f"‚úÖ {model} - Available")
        except Exception as e:
            error_msg = str(e).lower()
            if 'does not exist' in error_msg or 'not authorized' in error_msg:
                st.error(f"‚ùå {model} - Not authorized")
            else:
                st.warning(f"‚ö†Ô∏è {model} - Error: {str(e)[:50]}")
    
    return working_models
```

### Step 2: Use Test Function Before Scan

In the "CDE Scan" page, add a button to test models:

```python
if st.button("üîç Test Available Models"):
    available_models = test_available_models()
    st.success(f"Found {len(available_models)} working models")
    st.write("Available models:", available_models)
```

### Step 3: Better Error Handling in Cortex Calls

Replace your `call_cortex` function with this improved version:

```python
def call_cortex(prompt, model='mixtral-8x7b'):
    """Call Cortex AI with better error handling"""
    try:
        # Escape single quotes
        prompt_clean = prompt.replace("'", "''")
        
        # Truncate if too long
        if len(prompt_clean) > 15000:
            prompt_clean = prompt_clean[:15000]
        
        sql = f"""
        SELECT SNOWFLAKE.CORTEX.COMPLETE(
            '{model}',
            '{prompt_clean}'
        ) as response
        """
        
        result = session.sql(sql).collect()
        return result[0]['RESPONSE'] if result else ""
        
    except Exception as e:
        error_msg = str(e).lower()
        
        # Handle specific errors
        if 'does not exist' in error_msg:
            return f"‚ö†Ô∏è Error: Model '{model}' does not exist in your account"
        elif 'not authorized' in error_msg:
            return f"‚ö†Ô∏è Error: You are not authorized to use model '{model}'. Please check with your Snowflake admin."
        elif 'token' in error_msg and 'limit' in error_msg:
            return f"‚ö†Ô∏è Error: Input too long for model '{model}'"
        else:
            return f"‚ö†Ô∏è Error: {str(e)[:100]}"
```

### Step 4: Safe Model Selection

Update your model dropdown to only show working models:

```python
# At the top of your file, after session is created
@st.cache_data(ttl=3600)
def get_working_models():
    """Get list of models that actually work"""
    test_models = ['mixtral-8x7b', 'mistral-7b', 'llama3.1-70b', 'snowflake-arctic']
    working = []
    
    for model in test_models:
        try:
            result = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{model}', 'hi') as r").collect()
            if result:
                working.append(model)
        except:
            pass
    
    return working if working else ['mixtral-8x7b']  # Fallback

# Then in your UI:
available_models = get_working_models()

selected_model = st.selectbox(
    "Select AI Model",
    available_models,
    help=f"Only showing models available in your account ({len(available_models)} found)"
)
```

---

## QUICK TEST CHECKLIST

After applying fixes:

- [ ] Run the ALTER TABLE SQL to add AI_MODEL_USED column
- [ ] Verify column exists: `DESC TABLE CDE_SCAN_RESULTS;`
- [ ] Test which models work using the test function
- [ ] Update model dropdown to only show working models
- [ ] Try a small scan on 1-2 tables
- [ ] Check that results save without SQL error
- [ ] Verify AI reasoning works with selected model

---

## RECOMMENDED SAFE MODEL

If you're unsure which model to use, **`mixtral-8x7b`** is usually available in most Snowflake accounts and provides good balance of speed and accuracy.

To test it:
```sql
SELECT SNOWFLAKE.CORTEX.COMPLETE('mixtral-8x7b', 'hello') as response;
```

If that works, you're good to go!

---

## TROUBLESHOOTING

### Error persists after adding column?
- Refresh your Streamlit app (press R key)
- Clear Streamlit cache: `st.cache_data.clear()`
- Restart the Streamlit app completely

### No models work?
- Check if Cortex is enabled: Contact your Snowflake admin
- Check your role permissions: `SHOW GRANTS TO ROLE your_role;`
- Try from a Snowflake worksheet first to verify Cortex access

### Still getting authorization errors?
Your account might not have access to certain models. This is normal - Snowflake restricts some models by region or account type. Use the models that work in your account.

---

## FILES PROVIDED

1. **fix_add_ai_model_column.sql** - SQL to add missing column
2. **cde_app_FIXED.py** - Partially updated app with fixes
3. **This guide** - Quick fixes you can apply to your existing code

Choose the approach that works best for you:
- **Quick Fix**: Just apply the SQL and code changes from this guide
- **Full Replace**: Use the cde_app_FIXED.py file (larger refactor)

---

**Good luck! üöÄ**


import streamlit as st
import pandas as pd
import snowflake.snowpark as snowpark
from snowflake.snowpark import Session
import snowflake.snowpark.functions as F
from datetime import datetime
import re
import json

# Page configuration
st.set_page_config(
    page_title="CDE Management System (AI-Powered)",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .ai-badge {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 1rem;
        font-size: 0.8rem;
        font-weight: bold;
    }
    .intelligent-section {
        background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%);
        border-left: 4px solid #667eea;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .pattern-section {
        background: linear-gradient(135deg, #f093fb15 0%, #f5576c15 100%);
        border-left: 4px solid #f093fb;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .success-ai {
        background: linear-gradient(135deg, #11998e15 0%, #38ef7d15 100%);
        border-left: 4px solid #11998e;
        padding: 1rem;
        border-radius: 0.5rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .model-info {
        background: linear-gradient(135deg, #ffecd215 0%, #fcb69f15 100%);
        border-left: 4px solid #fcb69f;
        padding: 0.5rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        font-size: 0.85rem;
    }
</style>
""", unsafe_allow_html=True)

# Get Snowflake session
@st.cache_resource
def get_session():
    return snowpark.context.get_active_session()

try:
    session = get_session()
except:
    st.error("‚ùå Unable to connect to Snowflake session.")
    st.stop()

# ========================================================================
# DYNAMIC MODEL FETCHING - Gets available Cortex models from your account
# ========================================================================
@st.cache_data(ttl=3600)  # Cache for 1 hour
def get_available_cortex_models():
    """
    Dynamically fetch all available Cortex models in the current Snowflake account.
    Falls back to a comprehensive default list if dynamic fetching fails.
    """
    
    # Comprehensive list of all known Cortex models (as of Jan 2026)
    all_known_models = [
        # Claude models (Anthropic)
        'claude-3-5-sonnet-20250514',
        'claude-3-5-haiku-20250514',
        'claude-3-5-sonnet-20241022',
        'claude-3-haiku-20240307',
        'claude-3-sonnet-20240229',
        'claude-3-opus-20240229',
        
        # Snowflake models
        'snowflake-arctic',
        
        # Reka models
        'reka-core',
        'reka-flash',
        
        # Mistral models
        'mistral-large',
        'mistral-large2',
        'mistral-7b',
        'mixtral-8x7b',
        'mixtral-8x22b',
        
        # Meta Llama models
        'llama3-8b',
        'llama3-70b',
        'llama3.1-8b',
        'llama3.1-70b',
        'llama3.1-405b',
        'llama3.2-1b',
        'llama3.2-3b',
        'llama3.3-70b',
        
        # Google models
        'gemma-7b',
        'gemma2-9b',
        
        # AI21 Labs models
        'jamba-instruct',
        'jamba-1.5-mini',
        'jamba-1.5-large',
    ]
    
    try:
        # Method 1: Try to execute a simple completion with each model to test availability
        # This is the most reliable method but can be slow
        # We'll test a subset quickly
        
        available_models = []
        
        # Quick test on a few key models to determine if Cortex is working
        quick_test_models = ['mixtral-8x7b', 'snowflake-arctic', 'mistral-large2', 'llama3.1-70b']
        
        working = False
        for test_model in quick_test_models:
            try:
                session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{test_model}', 'hi') as response").collect()
                available_models.append(test_model)
                working = True
                break  # If one works, assume Cortex is available
            except:
                continue
        
        if working:
            # Cortex is available, return all known models
            # (We assume if one works, all supported models are available)
            return sorted(all_known_models)
        
        # Method 2: Try to query information schema or system views
        try:
            # Some Snowflake versions may have this
            result = session.sql("""
                SELECT MODEL_NAME 
                FROM SNOWFLAKE.INFORMATION_SCHEMA.CORTEX_MODELS
                ORDER BY MODEL_NAME
            """).collect()
            
            if result:
                models = [row['MODEL_NAME'] for row in result]
                return sorted(models)
        except:
            pass
        
        # Fallback: Return the comprehensive default list
        return sorted(all_known_models)
    
    except Exception as e:
        # If everything fails, return a curated default list of most common models
        return sorted([
            'mixtral-8x7b',                # Mistral (balanced) - RECOMMENDED DEFAULT
            'claude-3-5-sonnet-20250514',  # Claude 3.5 Sonnet (most capable)
            'claude-3-5-haiku-20250514',   # Claude 3.5 Haiku (fast)
            'snowflake-arctic',            # Snowflake's model
            'mistral-large2',              # Mistral (latest large)
            'llama3.1-70b',                # Meta (large)
            'llama3.1-405b',               # Meta (largest)
            'llama3.3-70b',                # Meta (latest)
            'reka-flash',                  # Reka (fast)
            'gemma-7b',                    # Google
            'jamba-1.5-large',             # AI21 Labs
        ])

# Model information helper
def get_model_info(model_name):
    """Return helpful information about each model"""
    model_descriptions = {
        'mixtral-8x7b': '‚ö° Balanced speed & accuracy - RECOMMENDED',
        'claude-3-5-sonnet-20250514': 'üéØ Most accurate - Best for complex analysis',
        'claude-3-5-haiku-20250514': 'üöÄ Fast & efficient - Good for quick tasks',
        'snowflake-arctic': '‚ùÑÔ∏è Snowflake optimized - Enterprise ready',
        'mistral-large2': 'üéì Latest Mistral - Very accurate',
        'mistral-large': 'üéì Mistral flagship - Very accurate',
        'mistral-7b': '‚ö° Small & fast - Good for simple tasks',
        'llama3.1-405b': 'ü¶ô Largest Llama - Maximum capability',
        'llama3.1-70b': 'ü¶ô Large Llama - Great balance',
        'llama3.1-8b': 'ü¶ô Small Llama - Fast responses',
        'llama3.3-70b': 'ü¶ô Latest Llama - Excellent quality',
        'llama3.2-3b': 'ü¶ô Tiny Llama - Very fast',
        'llama3.2-1b': 'ü¶ô Micro Llama - Fastest',
        'reka-flash': '‚ö° Reka fast - Quick responses',
        'reka-core': 'üéØ Reka capable - Good accuracy',
        'gemma-7b': 'üî∑ Google Gemma - Solid performance',
        'gemma2-9b': 'üî∑ Google Gemma 2 - Improved',
        'jamba-instruct': 'üî∂ AI21 Jamba - Instruction tuned',
        'jamba-1.5-large': 'üî∂ AI21 Jamba XL - Very capable',
        'jamba-1.5-mini': 'üî∂ AI21 Jamba Mini - Fast',
    }
    return model_descriptions.get(model_name, 'üìä LLM Model')

# Cortex Helper Function using SQL
def call_cortex(prompt, model='mixtral-8x7b'):
    """Call Cortex AI using SQL function"""
    try:
        # Escape single quotes in prompt
        prompt_clean = prompt.replace("'", "''")
        
        sql = f"""
        SELECT SNOWFLAKE.CORTEX.COMPLETE(
            '{model}',
            '{prompt_clean}'
        ) as response
        """
        
        result = session.sql(sql).collect()
        return result[0]['RESPONSE'] if result else ""
    except Exception as e:
        return f"Error calling Cortex with model {model}: {str(e)}"

# Exclusion Check Function
def is_excluded_column(column_name):
    """Check if column should be excluded from CDE scanning"""
    try:
        # Try to load exclusion patterns
        df_exclusions = session.table("CDE_EXCLUSION_PATTERNS").filter(F.col("IS_ACTIVE") == True).to_pandas()
        
        column_upper = column_name.upper()
        
        for _, exclusion in df_exclusions.iterrows():
            exclusion_type = exclusion['EXCLUSION_TYPE']
            exclusion_value = exclusion['EXCLUSION_VALUE'].upper()
            
            if exclusion_type == 'EXACT':
                if column_upper == exclusion_value:
                    return True, exclusion['EXCLUSION_REASON']
            
            elif exclusion_type == 'CONTAINS':
                if exclusion_value in column_upper:
                    return True, exclusion['EXCLUSION_REASON']
            
            elif exclusion_type == 'STARTS_WITH':
                if column_upper.startswith(exclusion_value):
                    return True, exclusion['EXCLUSION_REASON']
            
            elif exclusion_type == 'ENDS_WITH':
                if column_upper.endswith(exclusion_value):
                    return True, exclusion['EXCLUSION_REASON']
        
        return False, None
        
    except Exception as e:
        # If exclusion table doesn't exist, skip exclusion check
        return False, None

# Smart Exclusion with AI (optional - for edge cases)
def ai_should_exclude_column(column_name, table_name, data_type, model='mixtral-8x7b'):
    """Use AI to determine if column is technical/audit (fallback)"""
    prompt = f"""Is this database column a technical/audit/system column that should be excluded from business data analysis?

Column: {column_name}
Table: {table_name}
Type: {data_type}

Common technical columns: created_at, updated_by, record_id, version, etl_batch_id, hash, checksum, etc.

Answer ONLY: YES or NO"""
    
    try:
        result = call_cortex(prompt, model)
        return 'YES' in result.upper()
    except:
        return False

# Cortex AI Functions
def generate_pattern_suggestions(attribute_name, domain, model='mixtral-8x7b'):
    """Generate intelligent pattern suggestions using Cortex"""
    prompt = f"""You are a data governance expert. Given this data element:
    - Attribute Name: {attribute_name}
    - Domain: {domain}
    
    Generate 8 common database column name variations that might exist in real databases.
    Consider: abbreviations, prefixes, suffixes, underscores, common aliases.
    
    Return ONLY a JSON array of strings (no explanation):
    ["PATTERN1", "PATTERN2", ...]
    """
    
    try:
        result = call_cortex(prompt, model)
        # Extract JSON array from response
        result = result.strip()
        if '```' in result:
            result = result.split('```')[1].replace('json', '').strip()
        patterns = json.loads(result)
        return patterns if isinstance(patterns, list) else []
    except:
        return []

def generate_definition(attribute_name, domain, tag, model='mixtral-8x7b'):
    """Generate professional definition using Cortex"""
    prompt = f"""You are a data dictionary expert. Write a clear, professional definition for:
    - Attribute: {attribute_name}
    - Domain: {domain}
    - Tag: {tag}
    
    Requirements:
    - 2-3 sentences maximum
    - Professional tone
    - Include: what it is, why it matters, typical usage
    - No bullet points
    
    Return ONLY the definition text (no labels or formatting).
    """
    
    try:
        result = call_cortex(prompt, model)
        return result.strip()
    except Exception as e:
        return f"Error generating definition: {str(e)}"

def semantic_column_match(column_name, cde_list, context="", model='mixtral-8x7b'):
    """Find semantic matches using Cortex with strict validation"""
    cde_sample = cde_list[:20]  # Limit for token size
    
    prompt = f"""You are a STRICT data matching expert. Avoid false positives.
    
    Column to match: "{column_name}"
    Context: {context}
    
    Available CDEs:
    {chr(10).join([f"- {cde}" for cde in cde_sample])}
    
    STRICT MATCHING RULES:
    - Only match if column and CDE have SAME semantic meaning
    - Generic word overlap is NOT enough (HEATING_TYPE ‚â† CLAIM_TYPE)
    - Domain must match (actuarial ‚â† claims)
    - Context matters (EFFECTIVE_DATE ‚â† CLAIM_DATE_OF_LOSS)
    
    WRONG matches to avoid:
    - Different rate types (LAPSE_RATE ‚â† COMMISSION_RATE)
    - Different date types (CONTRACT_DATE ‚â† LOSS_DATE)
    - Different domains (property columns ‚â† insurance CDEs)
    
    Return ONLY:
    - The matched CDE name if TRULY similar (confidence > 85%)
    - "NONE" if no strong match
    
    No explanation, just the answer.
    """
    
    try:
        result = call_cortex(prompt, model)
        result = result.strip().strip('"').strip("'")
        return result if result != "NONE" else None
    except:
        return None

def generate_intelligent_reasoning(column_name, table_name, matched_cde, definition, data_type, is_pii, model='mixtral-8x7b'):
    """Generate intelligent match reasoning using Cortex with strict validation"""
    prompt = f"""You are a strict data governance analyst. Critically evaluate this CDE match:
    
    MATCH DETAILS:
    - Column: {column_name} (Type: {data_type})
    - Table: {table_name}
    - Matched CDE: {matched_cde}
    - Is PII: {is_pii}
    - Definition: {definition}
    
    CRITICAL EVALUATION:
    First, determine if this is a VALID match or FALSE POSITIVE.
    
    FALSE POSITIVE indicators:
    - Generic words matching (e.g., HEATING_TYPE ‚Üí CLAIM TYPE is WRONG)
    - Domain mismatch (e.g., property data ‚Üí claims domain is WRONG)
    - Context mismatch (e.g., EFFECTIVE_DATE in actuarial ‚Üí CLAIM DATE is WRONG)
    - Similar but different meaning (e.g., LAPSE_RATE ‚Üí COMMISSION_RATE is WRONG)
    
    If FALSE POSITIVE, start with: "‚ö†Ô∏è QUESTIONABLE MATCH"
    If VALID match, provide:
    1. Why this is a match (1 sentence)
    2. Data sensitivity (1 sentence)
    3. Recommended action (1 sentence)
    
    Return single paragraph, professional tone, max 150 words.
    """
    
    try:
        result = call_cortex(prompt, model)
        return result.strip()
    except Exception as e:
        return f"Standard match based on pattern matching. {definition[:100]}"

def validate_match_quality(column_name, table_name, matched_cde, definition, model='mistral-7b'):
    """AI validation of match quality"""
    prompt = f"""You are a data quality validator.
    
    MATCH TO VALIDATE:
    - Column: {column_name} in table {table_name}
    - Matched CDE: {matched_cde}
    - CDE Definition: {definition}
    
    Is this a TRUE MATCH or FALSE POSITIVE?
    
    Consider:
    - Semantic alignment
    - Context appropriateness
    - Definition relevance
    
    Return ONLY: TRUE or FALSE (nothing else)
    """
    
    try:
        result = call_cortex(prompt, model)
        return 'TRUE' in result.upper()
    except:
        return True  # Default to true if AI fails

def ai_classify_column(column_name, table_name, data_type, model='mixtral-8x7b'):
    """AI-powered column classification"""
    prompt = f"""You are a data classification expert.
    
    Classify this database column:
    - Column: {column_name}
    - Table: {table_name}
    - Data Type: {data_type}
    
    Provide:
    1. Likely Domain (Claims, Coverage, Financial, etc.)
    2. Likely Tag (Event Details, Financial Metrics, etc.)
    3. PII Status (Y or N)
    4. Confidence (0-100)
    
    Return as JSON:
    {{"domain": "...", "tag": "...", "is_pii": "Y/N", "confidence": 85}}
    """
    
    try:
        result = call_cortex(prompt, model)
        if '```' in result:
            result = result.split('```')[1].replace('json', '').strip()
        classification = json.loads(result)
        return classification
    except:
        return {"domain": "Unknown", "tag": "Unknown", "is_pii": "N", "confidence": 0}

# Helper function to generate unique scan run ID
def generate_scan_run_id():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    return f"SCAN_{timestamp}"

# Helper function to match patterns
def match_pattern(column_name, pattern_type, pattern_value):
    """Check if a column name matches a pattern with improved accuracy"""
    column_upper = column_name.upper()
    pattern_upper = pattern_value.upper()
    
    if pattern_type == 'EXACT':
        return column_upper == pattern_upper
    
    elif pattern_type == 'CONTAINS':
        # Improved CONTAINS logic to avoid false positives
        
        # If pattern is very short (1-2 chars), require exact word match
        if len(pattern_upper) <= 2:
            # Use word boundary matching for short patterns
            words = column_upper.replace('_', ' ').split()
            return pattern_upper in words
        
        # For patterns 3 chars or longer, check if it's a meaningful substring
        if pattern_upper in column_upper:
            # Additional validation: avoid matching if pattern is just part of a longer word
            # Example: Don't match "AGE" in "AGENT_CODE"
            
            # Find the position of the match
            idx = column_upper.find(pattern_upper)
            
            # Check if pattern is surrounded by word boundaries (_, space, or string edges)
            is_word_boundary_before = (idx == 0 or column_upper[idx - 1] in ['_', ' ', '-'])
            is_word_boundary_after = (idx + len(pattern_upper) >= len(column_upper) or 
                                     column_upper[idx + len(pattern_upper)] in ['_', ' ', '-'])
            
            # Pattern must be at word boundaries OR be 4+ characters long
            if is_word_boundary_before and is_word_boundary_after:
                return True
            elif len(pattern_upper) >= 4:  # Longer patterns can match within words
                return True
            else:
                return False
        
        return False
    
    elif pattern_type == 'STARTS_WITH':
        return column_upper.startswith(pattern_upper)
    
    elif pattern_type == 'ENDS_WITH':
        return column_upper.endswith(pattern_upper)
    
    elif pattern_type == 'REGEX':
        try:
            return bool(re.search(pattern_upper, column_upper))
        except:
            return False
    
    return False

# ==========================
# SIDEBAR & NAVIGATION
# ==========================
st.sidebar.markdown("# ü§ñ CDE Management")
st.sidebar.markdown("*Powered by Snowflake Cortex AI*")
st.sidebar.markdown("---")

# Display available models count in sidebar
try:
    available_models = get_available_cortex_models()
    st.sidebar.success(f"‚úÖ {len(available_models)} Cortex models available")
except:
    st.sidebar.info("üìä Loading models...")

page = st.sidebar.radio(
    "Navigate to:",
    [
        "üìã Reference Data Management",
        "üîç CDE Scan (Intelligent)",
        "üìä CDE Findings & Analysis",
        "üí¨ Ask Cortex AI"
    ],
    key="navigation"
)

st.sidebar.markdown("---")
st.sidebar.markdown("### üéØ AI Features")
st.sidebar.info("""
‚ú® **AI-Powered Features:**
- ü§ñ Pattern Suggestions
- ‚úçÔ∏è Auto Definitions
- üîç Semantic Matching
- üß† Intelligent Reasoning
- ‚úÖ Match Validation
- üí¨ Natural Language Q&A
""")

# ==================== SCREEN 1: REFERENCE DATA MANAGEMENT ====================
if page == "üìã Reference Data Management":
    st.markdown('<div class="main-header">üìã CDE Reference Data Management</div>', unsafe_allow_html=True)
    st.markdown('<span class="ai-badge">ü§ñ AI-ENHANCED</span>', unsafe_allow_html=True)
    
    # Create reference table if not exists
    try:
        session.sql("""
            CREATE TABLE IF NOT EXISTS CDE_REFERENCE (
                CDE_ID NUMBER AUTOINCREMENT,
                DOMAIN VARCHAR(200),
                TAG VARCHAR(200),
                ATTRIBUTE_LOGICAL_NAME VARCHAR(500),
                IS_PII VARCHAR(1),
                DEFINITION TEXT,
                CREATED_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
                CREATED_BY VARCHAR(100) DEFAULT CURRENT_USER(),
                UPDATED_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
                UPDATED_BY VARCHAR(100) DEFAULT CURRENT_USER(),
                IS_ACTIVE BOOLEAN DEFAULT TRUE,
                PRIMARY KEY (CDE_ID)
            )
        """).collect()
    except Exception as e:
        st.error(f"Error ensuring table exists: {str(e)}")
    
    # Tabs for different operations
    tab1, tab2, tab3, tab4 = st.tabs(["üìä View All", "‚ûï Add New (AI-Enhanced)", "‚úèÔ∏è Edit", "üóëÔ∏è Delete"])
    
    # TAB 1: View All
    with tab1:
        st.markdown("### Current CDE Reference Data")
        
        try:
            df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
            
            if len(df_ref) > 0:
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Total CDEs", len(df_ref))
                with col2:
                    st.metric("Unique Domains", df_ref['DOMAIN'].nunique())
                with col3:
                    st.metric("PII Elements", len(df_ref[df_ref['IS_PII'] == 'Y']))
                with col4:
                    st.metric("Unique Tags", df_ref['TAG'].nunique())
                
                st.markdown("---")
                
                # Filters
                col1, col2, col3 = st.columns(3)
                with col1:
                    filter_domain = st.multiselect(
                        "Filter by Domain",
                        options=sorted(df_ref['DOMAIN'].dropna().unique().tolist()),
                        default=[]
                    )
                with col2:
                    filter_tag = st.multiselect(
                        "Filter by Tag",
                        options=sorted(df_ref['TAG'].dropna().unique().tolist()),
                        default=[]
                    )
                with col3:
                    filter_pii = st.selectbox("Filter by PII", options=["All", "Y", "N"])
                
                # Apply filters
                filtered_df = df_ref.copy()
                if filter_domain:
                    filtered_df = filtered_df[filtered_df['DOMAIN'].isin(filter_domain)]
                if filter_tag:
                    filtered_df = filtered_df[filtered_df['TAG'].isin(filter_tag)]
                if filter_pii != "All":
                    filtered_df = filtered_df[filtered_df['IS_PII'] == filter_pii]
                
                st.info(f"Showing {len(filtered_df)} of {len(df_ref)} records")
                
                st.dataframe(
                    filtered_df[['CDE_ID', 'DOMAIN', 'TAG', 'ATTRIBUTE_LOGICAL_NAME', 'IS_PII', 'DEFINITION']],
                    use_container_width=True,
                    height=500
                )
                
                csv = filtered_df.to_csv(index=False)
                st.download_button(
                    label="üì• Download as CSV",
                    data=csv,
                    file_name=f"cde_reference_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
                
            else:
                st.warning("‚ö†Ô∏è No reference data found. Please add CDE definitions.")
        except Exception as e:
            st.error(f"Error loading reference data: {str(e)}")
    
    # TAB 2: Add New - AI ENHANCED
    with tab2:
        st.markdown("### Add New CDE Definition")
        st.markdown('<span class="ai-badge">ü§ñ AI-POWERED</span>', unsafe_allow_html=True)
        
        # Manual Entry Section
        st.markdown('<div class="pattern-section">', unsafe_allow_html=True)
        st.markdown("#### üìù Manual Entry")
        
        with st.form("add_cde_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                add_domain = st.text_input("Domain *", placeholder="e.g., Claims, Coverage/Rider")
                add_tag = st.text_input("Tag *", placeholder="e.g., Event Details, Financial Metrics")
                add_attr_name = st.text_input("Attribute Logical Name *", placeholder="e.g., CLAIM_DATE_OF_LOSS")
            
            with col2:
                add_is_pii = st.selectbox("Is PII? *", options=["N", "Y"])
                add_definition = st.text_area("Definition *", placeholder="Detailed description", height=120)
            
            submit_add = st.form_submit_button("‚ûï Add CDE", type="primary")
            
            if submit_add:
                if not add_domain or not add_tag or not add_attr_name or not add_definition:
                    st.error("‚ùå Please fill in all required fields (*)")
                else:
                    try:
                        domain_clean = add_domain.replace("'", "''")
                        tag_clean = add_tag.replace("'", "''")
                        attr_clean = add_attr_name.replace("'", "''")
                        def_clean = add_definition.replace("'", "''")
                        
                        insert_query = f"""
                        INSERT INTO CDE_REFERENCE (DOMAIN, TAG, ATTRIBUTE_LOGICAL_NAME, IS_PII, DEFINITION)
                        VALUES ('{domain_clean}', '{tag_clean}', '{attr_clean}', '{add_is_pii}', '{def_clean}')
                        """
                        session.sql(insert_query).collect()
                        st.success(f"‚úÖ Successfully added CDE: **{add_attr_name}**")
                        st.balloons()
                        st.rerun()
                    except Exception as e:
                        st.error(f"‚ùå Error adding CDE: {str(e)}")
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # AI Assistant Section
        st.markdown('<div class="intelligent-section">', unsafe_allow_html=True)
        st.markdown("#### ü§ñ AI Assistant")
        st.markdown("*Use Cortex AI to help create your CDE definition*")
        
        # Model selector for AI assistant
        ai_models = get_available_cortex_models()
        ai_assistant_model = st.selectbox(
            "AI Model for Assistant",
            ai_models,
            index=ai_models.index('mixtral-8x7b') if 'mixtral-8x7b' in ai_models else 0,
            help="Select which Cortex model to use for AI assistance"
        )
        st.markdown(f'<div class="model-info">üìä Using: {get_model_info(ai_assistant_model)}</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            ai_attr_name = st.text_input("Attribute Name", key="ai_attr", placeholder="e.g., CUSTOMER_SSN")
            ai_domain = st.text_input("Domain", key="ai_domain", placeholder="e.g., New Business")
        
        with col2:
            ai_tag = st.text_input("Tag", key="ai_tag", placeholder="e.g., Applicant Info")
        
        st.markdown("---")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ü§ñ Generate Pattern Suggestions", type="secondary", use_container_width=True):
                if ai_attr_name and ai_domain:
                    with st.spinner("ü§ñ AI is thinking..."):
                        patterns = generate_pattern_suggestions(ai_attr_name, ai_domain, ai_assistant_model)
                        if patterns:
                            st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                            st.markdown("**üí° AI-Generated Pattern Suggestions:**")
                            st.code(", ".join(patterns))
                            st.markdown("*Use these to create pattern rules in CDE_PATTERN_RULES table*")
                            st.markdown('</div>', unsafe_allow_html=True)
                        else:
                            st.warning("Could not generate patterns")
                else:
                    st.warning("Please enter Attribute Name and Domain")
        
        with col2:
            if st.button("‚úçÔ∏è Generate Definition", type="secondary", use_container_width=True):
                if ai_attr_name and ai_domain:
                    with st.spinner("ü§ñ AI is writing..."):
                        definition = generate_definition(ai_attr_name, ai_domain, ai_tag or "General", ai_assistant_model)
                        if definition:
                            st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                            st.markdown("**üìù AI-Generated Definition:**")
                            st.info(definition)
                            st.markdown('</div>', unsafe_allow_html=True)
                else:
                    st.warning("Please enter Attribute Name and Domain")
        
        with col3:
            if st.button("üéØ Suggest Classification", type="secondary", use_container_width=True):
                if ai_attr_name:
                    with st.spinner("ü§ñ AI is analyzing..."):
                        classification = ai_classify_column(ai_attr_name, "N/A", "VARCHAR", ai_assistant_model)
                        st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                        st.markdown("**üéØ AI Classification:**")
                        st.write(f"**Domain:** {classification.get('domain', 'Unknown')}")
                        st.write(f"**Tag:** {classification.get('tag', 'Unknown')}")
                        st.write(f"**PII:** {classification.get('is_pii', 'N')}")
                        st.write(f"**Confidence:** {classification.get('confidence', 0)}%")
                        st.markdown('</div>', unsafe_allow_html=True)
                else:
                    st.warning("Please enter Attribute Name")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # TAB 3 & 4: Edit and Delete (keeping simple - no AI needed here)
    with tab3:
        st.markdown("### Edit Existing CDE Definition")
        
        try:
            df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
            
            if len(df_ref) > 0:
                cde_options = df_ref.apply(
                    lambda x: f"{x['CDE_ID']} - {x['DOMAIN']} - {x['ATTRIBUTE_LOGICAL_NAME']}", 
                    axis=1
                ).tolist()
                
                selected_cde = st.selectbox("Select CDE to Edit", options=cde_options)
                
                if selected_cde:
                    cde_id = int(selected_cde.split(" - ")[0])
                    current_data = df_ref[df_ref['CDE_ID'] == cde_id].iloc[0]
                    
                    with st.form("edit_cde_form"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            edit_domain = st.text_input("Domain *", value=current_data['DOMAIN'])
                            edit_tag = st.text_input("Tag *", value=current_data['TAG'])
                            edit_attr_name = st.text_input("Attribute Logical Name *", value=current_data['ATTRIBUTE_LOGICAL_NAME'])
                        
                        with col2:
                            edit_is_pii = st.selectbox("Is PII? *", options=["Y", "N"], index=0 if current_data['IS_PII'] == 'Y' else 1)
                            edit_definition = st.text_area("Definition *", value=current_data['DEFINITION'] if pd.notna(current_data['DEFINITION']) else "", height=120)
                        
                        submit_edit = st.form_submit_button("üíæ Update", type="primary")
                        
                        if submit_edit:
                            try:
                                domain_clean = edit_domain.replace("'", "''")
                                tag_clean = edit_tag.replace("'", "''")
                                attr_clean = edit_attr_name.replace("'", "''")
                                def_clean = edit_definition.replace("'", "''")
                                
                                update_query = f"""
                                UPDATE CDE_REFERENCE SET
                                    DOMAIN = '{domain_clean}',
                                    TAG = '{tag_clean}',
                                    ATTRIBUTE_LOGICAL_NAME = '{attr_clean}',
                                    IS_PII = '{edit_is_pii}',
                                    DEFINITION = '{def_clean}',
                                    UPDATED_DATE = CURRENT_TIMESTAMP(),
                                    UPDATED_BY = CURRENT_USER()
                                WHERE CDE_ID = {cde_id}
                                """
                                session.sql(update_query).collect()
                                st.success(f"‚úÖ Successfully updated CDE ID {cde_id}")
                                st.rerun()
                            except Exception as e:
                                st.error(f"‚ùå Error updating CDE: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è No CDE definitions available to edit.")
        except Exception as e:
            st.error(f"‚ùå Error loading data: {str(e)}")
    
    with tab4:
        st.markdown("### Delete CDE Definition")
        st.warning("‚ö†Ô∏è This will soft-delete the record (set IS_ACTIVE = FALSE)")
        
        try:
            df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
            
            if len(df_ref) > 0:
                cde_options = df_ref.apply(
                    lambda x: f"{x['CDE_ID']} - {x['DOMAIN']} - {x['ATTRIBUTE_LOGICAL_NAME']}", 
                    axis=1
                ).tolist()
                
                selected_delete = st.selectbox("Select CDE to Delete", options=cde_options, key="delete_select")
                
                if selected_delete:
                    cde_id = int(selected_delete.split(" - ")[0])
                    current_data = df_ref[df_ref['CDE_ID'] == cde_id].iloc[0]
                    
                    st.markdown("**Record to Delete:**")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**Domain:** {current_data['DOMAIN']}")
                        st.write(f"**Tag:** {current_data['TAG']}")
                    with col2:
                        st.write(f"**Attribute:** {current_data['ATTRIBUTE_LOGICAL_NAME']}")
                        st.write(f"**Is PII:** {current_data['IS_PII']}")
                    
                    if st.button("üóëÔ∏è Confirm Delete", type="primary"):
                        try:
                            delete_query = f"""
                            UPDATE CDE_REFERENCE 
                            SET IS_ACTIVE = FALSE, UPDATED_DATE = CURRENT_TIMESTAMP(), UPDATED_BY = CURRENT_USER()
                            WHERE CDE_ID = {cde_id}
                            """
                            session.sql(delete_query).collect()
                            st.success(f"‚úÖ CDE ID {cde_id} deleted")
                            st.rerun()
                        except Exception as e:
                            st.error(f"‚ùå Error: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è No CDE definitions available.")
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")

# ==================== SCREEN 2: CDE SCAN (INTELLIGENT) ====================
elif page == "üîç CDE Scan (Intelligent)":
    st.markdown('<div class="main-header">üîç Intelligent CDE Scan</div>', unsafe_allow_html=True)
    st.markdown('<span class="ai-badge">ü§ñ AI-POWERED MATCHING</span>', unsafe_allow_html=True)
    
    # Create scan results table
    try:
        session.sql("""
            CREATE TABLE IF NOT EXISTS CDE_SCAN_RESULTS (
                SCAN_ID NUMBER AUTOINCREMENT,
                SCAN_RUN_ID VARCHAR(100),
                SCAN_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
                SCAN_USER VARCHAR(100) DEFAULT CURRENT_USER(),
                DATABASE_NAME VARCHAR(200),
                SCHEMA_NAME VARCHAR(200),
                TABLE_NAME VARCHAR(200),
                COLUMN_NAME VARCHAR(200),
                DATA_TYPE VARCHAR(100),
                MATCHED_CDE_ID NUMBER,
                MATCHED_DOMAIN VARCHAR(200),
                MATCHED_TAG VARCHAR(200),
                MATCHED_ATTRIBUTE_LOGICAL_NAME VARCHAR(500),
                MATCHED_IS_PII VARCHAR(1),
                MATCHED_DEFINITION TEXT,
                PATTERN_ID NUMBER,
                PATTERN_TYPE VARCHAR(50),
                PATTERN_VALUE VARCHAR(500),
                MATCH_SCORE NUMBER(5,2),
                MATCH_REASON VARCHAR(2000),
                MATCH_METHOD VARCHAR(50),
                AI_VALIDATED BOOLEAN,
                AI_MODEL_USED VARCHAR(100),
                IS_REVIEWED BOOLEAN DEFAULT FALSE,
                REVIEW_STATUS VARCHAR(50),
                REVIEW_NOTES TEXT,
                REVIEWED_BY VARCHAR(100),
                REVIEWED_DATE TIMESTAMP_NTZ,
                PRIMARY KEY (SCAN_ID)
            )
        """).collect()
    except Exception as e:
        st.error(f"Error: {str(e)}")
    
    st.markdown("---")
    
    # Scan Configuration
    st.markdown("### ‚öôÔ∏è Scan Configuration")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        scan_mode = st.selectbox(
            "Scan Mode",
            ["Pattern + AI", "Pattern Only", "AI Only"],
            help="Pattern+AI: Best accuracy (slower) | Pattern Only: Fast | AI Only: Experimental"
        )
    
    with col2:
        # Get available models dynamically
        model_list = get_available_cortex_models()
        
        # Set default model
        default_model = 'mixtral-8x7b'
        default_index = model_list.index(default_model) if default_model in model_list else 0
        
        selected_llm = st.selectbox(
            "LLM Model for AI Matching",
            model_list,
            index=default_index,
            help="Select Cortex AI model for semantic matching"
        )
        
        # Show model info
        st.markdown(f'<div class="model-info">{get_model_info(selected_llm)}</div>', unsafe_allow_html=True)
    
    with col3:
        ai_confidence = st.slider(
            "AI Confidence Threshold",
            min_value=70,
            max_value=95,
            value=85,
            step=5,
            help="Minimum confidence for AI matches (higher = fewer but more accurate matches)"
        )
    
    st.markdown("---")
    
    # Database and Schema Selection
    st.markdown("### üéØ Select Scan Scope")
    
    col1, col2 = st.columns(2)
    
    with col1:
        try:
            databases = session.sql("SHOW DATABASES").collect()
            db_list = [row['name'] for row in databases]
            selected_db = st.selectbox("Select Database *", db_list, key="scan_db")
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")
            selected_db = None
    
    with col2:
        if selected_db:
            try:
                schemas = session.sql(f"SHOW SCHEMAS IN DATABASE {selected_db}").collect()
                schema_list = [row['name'] for row in schemas]
                selected_schema = st.selectbox("Select Schema *", schema_list, key="scan_schema")
            except Exception as e:
                st.error(f"‚ùå Error: {str(e)}")
                selected_schema = None
        else:
            selected_schema = None
    
    if selected_db and selected_schema:
        st.success(f"üìç **Scan Scope:** `{selected_db}.{selected_schema}` | **Mode:** {scan_mode} | **Model:** {selected_llm}")
        
        st.markdown("---")
        
        col1, col2 = st.columns([1, 1])
        with col1:
            start_scan = st.button("ü§ñ Start Intelligent Scan", type="primary", use_container_width=True)
        with col2:
            preview_tables = st.button("üëÅÔ∏è Preview Tables", use_container_width=True)
        
        if preview_tables:
            try:
                preview_query = f"""
                SELECT TABLE_NAME, COUNT(*) as COLUMN_COUNT
                FROM {selected_db}.INFORMATION_SCHEMA.COLUMNS
                WHERE TABLE_SCHEMA = '{selected_schema}'
                GROUP BY TABLE_NAME
                ORDER BY TABLE_NAME
                """
                df_preview = session.sql(preview_query).to_pandas()
                
                if len(df_preview) > 0:
                    st.info(f"üìä Found **{len(df_preview)}** tables with **{df_preview['COLUMN_COUNT'].sum()}** columns")
                    st.dataframe(df_preview, use_container_width=True, height=300)
                else:
                    st.warning(f"No tables found")
            except Exception as e:
                st.error(f"Error: {str(e)}")
        
        if start_scan:
            scan_run_id = generate_scan_run_id()
            
            with st.spinner(f"ü§ñ {'Intelligent' if 'AI' in scan_mode else 'Pattern'} scanning in progress using {selected_llm}..."):
                try:
                    # Get columns
                    columns_query = f"""
                    SELECT TABLE_CATALOG as DATABASE_NAME, TABLE_SCHEMA as SCHEMA_NAME,
                           TABLE_NAME, COLUMN_NAME, DATA_TYPE
                    FROM {selected_db}.INFORMATION_SCHEMA.COLUMNS
                    WHERE TABLE_SCHEMA = '{selected_schema}'
                    ORDER BY TABLE_NAME, ORDINAL_POSITION
                    """
                    
                    df_columns = session.sql(columns_query).to_pandas()
                    
                    if len(df_columns) == 0:
                        st.warning(f"‚ö†Ô∏è No tables found")
                    else:
                        st.info(f"üìä Scanning **{len(df_columns)}** columns across **{df_columns['TABLE_NAME'].nunique()}** tables using **{selected_llm}**")
                        
                        df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
                        
                        if len(df_ref) == 0:
                            st.error("‚ùå No CDE reference patterns found")
                        else:
                            # Get pattern rules
                            try:
                                df_patterns = session.table("CDE_PATTERN_RULES").filter(F.col("IS_ACTIVE") == True).to_pandas()
                            except:
                                df_patterns = pd.DataFrame({
                                    'PATTERN_ID': range(len(df_ref)),
                                    'CDE_ID': df_ref['CDE_ID'],
                                    'PATTERN_TYPE': 'EXACT',
                                    'PATTERN_VALUE': df_ref['ATTRIBUTE_LOGICAL_NAME'],
                                    'PATTERN_PRIORITY': 10
                                })
                            
                            matches = []
                            excluded_columns = []
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            # Prepare CDE list for semantic matching
                            cde_list = df_ref['ATTRIBUTE_LOGICAL_NAME'].tolist()
                            
                            total_columns = len(df_columns)
                            ai_matches_count = 0
                            pattern_matches_count = 0
                            excluded_count = 0
                            
                            for idx, col_row in df_columns.iterrows():
                                progress_bar.progress((idx + 1) / total_columns)
                                status_text.text(f"Scanning {idx + 1}/{total_columns}: {col_row['COLUMN_NAME']}")
                                
                                column_name = col_row['COLUMN_NAME']
                                
                                # CHECK EXCLUSION LIST FIRST
                                is_excluded, exclusion_reason = is_excluded_column(column_name)
                                
                                if is_excluded:
                                    excluded_count += 1
                                    excluded_columns.append({
                                        'COLUMN_NAME': column_name,
                                        'TABLE_NAME': col_row['TABLE_NAME'],
                                        'REASON': exclusion_reason
                                    })
                                    continue
                                
                                pattern_matched = False
                                
                                # PATTERN MATCHING (if enabled)
                                if scan_mode in ["Pattern + AI", "Pattern Only"]:
                                    for _, pattern_row in df_patterns.iterrows():
                                        if match_pattern(column_name, pattern_row['PATTERN_TYPE'], pattern_row['PATTERN_VALUE']):
                                            cde_data = df_ref[df_ref['CDE_ID'] == pattern_row['CDE_ID']].iloc[0]
                                            
                                            match_score = 100.0 if pattern_row['PATTERN_TYPE'] == 'EXACT' else 80.0
                                            
                                            # Use AI for reasoning if in AI mode
                                            if scan_mode == "Pattern + AI":
                                                match_reason = generate_intelligent_reasoning(
                                                    column_name, col_row['TABLE_NAME'], 
                                                    cde_data['ATTRIBUTE_LOGICAL_NAME'],
                                                    cde_data['DEFINITION'],
                                                    col_row['DATA_TYPE'],
                                                    cde_data['IS_PII'],
                                                    selected_llm  # Use selected model
                                                )
                                            else:
                                                match_reason = f"Pattern match: {pattern_row['PATTERN_TYPE']} - {cde_data['DEFINITION'][:150]}"
                                            
                                            matches.append({
                                                'SCAN_RUN_ID': scan_run_id,
                                                'DATABASE_NAME': col_row['DATABASE_NAME'],
                                                'SCHEMA_NAME': col_row['SCHEMA_NAME'],
                                                'TABLE_NAME': col_row['TABLE_NAME'],
                                                'COLUMN_NAME': col_row['COLUMN_NAME'],
                                                'DATA_TYPE': col_row['DATA_TYPE'],
                                                'MATCHED_CDE_ID': int(cde_data['CDE_ID']),
                                                'MATCHED_DOMAIN': cde_data['DOMAIN'],
                                                'MATCHED_TAG': cde_data['TAG'],
                                                'MATCHED_ATTRIBUTE_LOGICAL_NAME': cde_data['ATTRIBUTE_LOGICAL_NAME'],
                                                'MATCHED_IS_PII': cde_data['IS_PII'],
                                                'MATCHED_DEFINITION': cde_data['DEFINITION'],
                                                'PATTERN_ID': int(pattern_row['PATTERN_ID']) if 'PATTERN_ID' in pattern_row else None,
                                                'PATTERN_TYPE': pattern_row['PATTERN_TYPE'],
                                                'PATTERN_VALUE': pattern_row['PATTERN_VALUE'],
                                                'MATCH_SCORE': match_score,
                                                'MATCH_REASON': match_reason,
                                                'MATCH_METHOD': 'Pattern',
                                                'AI_VALIDATED': scan_mode == "Pattern + AI",
                                                'AI_MODEL_USED': selected_llm if scan_mode == "Pattern + AI" else None
                                            })
                                            pattern_matched = True
                                            pattern_matches_count += 1
                                            break
                                
                                # AI SEMANTIC MATCHING (if enabled and no pattern match)
                                if not pattern_matched and scan_mode in ["Pattern + AI", "AI Only"]:
                                    context = f"Table: {col_row['TABLE_NAME']}, Type: {col_row['DATA_TYPE']}"
                                    semantic_match_result = semantic_column_match(column_name, cde_list, context, selected_llm)
                                    
                                    if semantic_match_result and semantic_match_result in cde_list:
                                        cde_data = df_ref[df_ref['ATTRIBUTE_LOGICAL_NAME'] == semantic_match_result].iloc[0]
                                        
                                        match_reason = generate_intelligent_reasoning(
                                            column_name, col_row['TABLE_NAME'],
                                            cde_data['ATTRIBUTE_LOGICAL_NAME'],
                                            cde_data['DEFINITION'],
                                            col_row['DATA_TYPE'],
                                            cde_data['IS_PII'],
                                            selected_llm  # Use selected model
                                        )
                                        
                                        matches.append({
                                            'SCAN_RUN_ID': scan_run_id,
                                            'DATABASE_NAME': col_row['DATABASE_NAME'],
                                            'SCHEMA_NAME': col_row['SCHEMA_NAME'],
                                            'TABLE_NAME': col_row['TABLE_NAME'],
                                            'COLUMN_NAME': col_row['COLUMN_NAME'],
                                            'DATA_TYPE': col_row['DATA_TYPE'],
                                            'MATCHED_CDE_ID': int(cde_data['CDE_ID']),
                                            'MATCHED_DOMAIN': cde_data['DOMAIN'],
                                            'MATCHED_TAG': cde_data['TAG'],
                                            'MATCHED_ATTRIBUTE_LOGICAL_NAME': cde_data['ATTRIBUTE_LOGICAL_NAME'],
                                            'MATCHED_IS_PII': cde_data['IS_PII'],
                                            'MATCHED_DEFINITION': cde_data['DEFINITION'],
                                            'PATTERN_ID': None,
                                            'PATTERN_TYPE': 'AI_SEMANTIC',
                                            'PATTERN_VALUE': semantic_match_result,
                                            'MATCH_SCORE': 75.0,
                                            'MATCH_REASON': match_reason,
                                            'MATCH_METHOD': 'AI Semantic',
                                            'AI_VALIDATED': True,
                                            'AI_MODEL_USED': selected_llm
                                        })
                                        ai_matches_count += 1
                            
                            progress_bar.empty()
                            status_text.empty()
                            
                            if len(matches) > 0:
                                # Auto-save
                                try:
                                    for match in matches:
                                        def_clean = match['MATCHED_DEFINITION'].replace("'", "''") if match['MATCHED_DEFINITION'] else ''
                                        reason_clean = match['MATCH_REASON'].replace("'", "''")
                                        
                                        insert_query = f"""
                                        INSERT INTO CDE_SCAN_RESULTS (
                                            SCAN_RUN_ID, DATABASE_NAME, SCHEMA_NAME, TABLE_NAME, COLUMN_NAME, DATA_TYPE,
                                            MATCHED_CDE_ID, MATCHED_DOMAIN, MATCHED_TAG, MATCHED_ATTRIBUTE_LOGICAL_NAME,
                                            MATCHED_IS_PII, MATCHED_DEFINITION, PATTERN_ID, PATTERN_TYPE, PATTERN_VALUE,
                                            MATCH_SCORE, MATCH_REASON, MATCH_METHOD, AI_VALIDATED, AI_MODEL_USED
                                        ) VALUES (
                                            '{match['SCAN_RUN_ID']}', '{match['DATABASE_NAME']}', '{match['SCHEMA_NAME']}',
                                            '{match['TABLE_NAME']}', '{match['COLUMN_NAME']}', '{match['DATA_TYPE']}',
                                            {match['MATCHED_CDE_ID']}, '{match['MATCHED_DOMAIN']}', '{match['MATCHED_TAG']}',
                                            '{match['MATCHED_ATTRIBUTE_LOGICAL_NAME']}', '{match['MATCHED_IS_PII']}', '{def_clean}',
                                            {match['PATTERN_ID'] if match['PATTERN_ID'] else 'NULL'}, '{match['PATTERN_TYPE']}',
                                            '{match['PATTERN_VALUE']}', {match['MATCH_SCORE']}, '{reason_clean}',
                                            '{match['MATCH_METHOD']}', {match['AI_VALIDATED']}, 
                                            {'NULL' if not match.get('AI_MODEL_USED') else f"'{match['AI_MODEL_USED']}'" }
                                        )
                                        """
                                        session.sql(insert_query).collect()
                                    
                                    st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                                    st.markdown(f"### ‚úÖ Scan Complete!")
                                    st.markdown(f"**Total CDEs Found:** {len(matches)}")
                                    st.markdown(f"**Pattern Matches:** {pattern_matches_count} | **AI Matches:** {ai_matches_count}")
                                    st.markdown(f"**Excluded Columns:** {excluded_count} (audit/system columns)")
                                    st.markdown(f"**AI Model Used:** {selected_llm}")
                                    st.markdown('</div>', unsafe_allow_html=True)
                                    
                                except Exception as save_error:
                                    st.warning(f"‚ö†Ô∏è Found {len(matches)} but save failed: {str(save_error)}")
                                
                                df_matches = pd.DataFrame(matches)
                                
                                # Summary metrics
                                col1, col2, col3, col4, col5 = st.columns(5)
                                with col1:
                                    st.metric("CDEs Found", len(df_matches))
                                with col2:
                                    st.metric("PII Elements", len(df_matches[df_matches['MATCHED_IS_PII'] == 'Y']))
                                with col3:
                                    st.metric("Tables Affected", df_matches['TABLE_NAME'].nunique())
                                with col4:
                                    st.metric("AI Matches", ai_matches_count)
                                with col5:
                                    st.metric("Excluded", excluded_count, help="Audit/system columns filtered out")
                                
                                # Show excluded columns summary
                                if excluded_count > 0:
                                    with st.expander(f"üö´ View {excluded_count} Excluded Columns"):
                                        df_excluded = pd.DataFrame(excluded_columns)
                                        st.dataframe(df_excluded, use_container_width=True)
                                        st.caption("These columns were filtered out as audit/system columns. To modify exclusions, update CDE_EXCLUSION_PATTERNS table.")
                                
                                st.markdown("---")
                                st.markdown("### üìã Scan Results")
                                
                                # Display with method badges
                                for idx, row in df_matches.iterrows():
                                    method_badge = "ü§ñ AI" if row['MATCH_METHOD'] == 'AI Semantic' else "üìê Pattern"
                                    pii_icon = "üî¥" if row['MATCHED_IS_PII'] == 'Y' else "üü¢"
                                    
                                    with st.expander(
                                        f"{pii_icon} {method_badge} | {row['TABLE_NAME']}.{row['COLUMN_NAME']} ‚Üí {row['MATCHED_ATTRIBUTE_LOGICAL_NAME']}"
                                    ):
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.write(f"**Domain:** {row['MATCHED_DOMAIN']}")
                                            st.write(f"**Tag:** {row['MATCHED_TAG']}")
                                            st.write(f"**Data Type:** {row['DATA_TYPE']}")
                                            st.write(f"**Is PII:** {row['MATCHED_IS_PII']}")
                                        with col2:
                                            st.write(f"**Match Method:** {row['MATCH_METHOD']}")
                                            st.write(f"**Pattern Type:** {row['PATTERN_TYPE']}")
                                            st.write(f"**Match Score:** {row['MATCH_SCORE']:.0f}%")
                                            st.write(f"**AI Model:** {row.get('AI_MODEL_USED', 'N/A')}")
                                        
                                        st.markdown("**üß† Intelligent Match Reasoning:**")
                                        st.info(row['MATCH_REASON'])
                                
                                st.markdown("---")
                                csv = df_matches.to_csv(index=False)
                                st.download_button(
                                    label="üì• Download Results as CSV",
                                    data=csv,
                                    file_name=f"cde_scan_{scan_run_id}.csv",
                                    mime="text/csv"
                                )
                            else:
                                st.warning("‚ö†Ô∏è No CDEs found")
                
                except Exception as e:
                    st.error(f"‚ùå Error during scan: {str(e)}")
                    st.exception(e)

# ==================== SCREEN 3: CDE FINDINGS & ANALYSIS ====================
elif page == "üìä CDE Findings & Analysis":
    st.markdown('<div class="main-header">üìä CDE Findings & Analysis</div>', unsafe_allow_html=True)
    st.markdown('<span class="ai-badge">ü§ñ AI-ENHANCED</span>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("üîÑ Refresh Data", type="secondary"):
            st.rerun()
    
    try:
        df_results = session.sql("SELECT * FROM CDE_SCAN_RESULTS ORDER BY SCAN_DATE DESC").to_pandas()
        
        if len(df_results) == 0:
            st.info("‚ÑπÔ∏è No scan results found. Please run a CDE scan first.")
        else:
            # Summary metrics
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                st.metric("Total CDEs", len(df_results))
            with col2:
                st.metric("PII Elements", len(df_results[df_results['MATCHED_IS_PII'] == 'Y']))
            with col3:
                st.metric("Tables", df_results['TABLE_NAME'].nunique())
            with col4:
                ai_count = len(df_results[df_results['MATCH_METHOD'] == 'AI Semantic']) if 'MATCH_METHOD' in df_results.columns else 0
                st.metric("AI Matches", ai_count)
            with col5:
                avg_score = df_results['MATCH_SCORE'].mean() if 'MATCH_SCORE' in df_results.columns else 0
                st.metric("Avg Score", f"{avg_score:.0f}%")
            
            # Show which AI models were used
            if 'AI_MODEL_USED' in df_results.columns:
                models_used = df_results['AI_MODEL_USED'].dropna().unique()
                if len(models_used) > 0:
                    st.info(f"ü§ñ AI Models Used: {', '.join(models_used)}")
            
            st.markdown("---")
            
            # Filters
            st.markdown("### üîç Filter Results")
            
            # First row of filters
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                # Get all domains from reference table for complete list
                try:
                    all_domains = session.sql("SELECT DISTINCT DOMAIN FROM CDE_REFERENCE WHERE IS_ACTIVE = TRUE ORDER BY DOMAIN").to_pandas()
                    domain_options = all_domains['DOMAIN'].tolist() if len(all_domains) > 0 else sorted(df_results['MATCHED_DOMAIN'].dropna().unique())
                except:
                    domain_options = sorted(df_results['MATCHED_DOMAIN'].dropna().unique())
                
                filter_domain = st.multiselect("Domain", options=domain_options, default=[])
            
            with col2:
                # Get all tags from reference table
                try:
                    all_tags = session.sql("SELECT DISTINCT TAG FROM CDE_REFERENCE WHERE IS_ACTIVE = TRUE ORDER BY TAG").to_pandas()
                    tag_options = all_tags['TAG'].tolist() if len(all_tags) > 0 else sorted(df_results['MATCHED_TAG'].dropna().unique())
                except:
                    tag_options = sorted(df_results['MATCHED_TAG'].dropna().unique())
                
                filter_tag = st.multiselect("Tag", options=tag_options, default=[])
            
            with col3:
                filter_pii = st.multiselect("PII Status", options=['Y', 'N'], default=[])
            
            with col4:
                if 'MATCH_METHOD' in df_results.columns:
                    filter_method = st.multiselect("Match Method", options=sorted(df_results['MATCH_METHOD'].unique()), default=[])
                else:
                    filter_method = []
            
            # Second row of filters
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                filter_database = st.multiselect("Database", options=sorted(df_results['DATABASE_NAME'].unique()), default=[])
            
            with col2:
                filter_schema = st.multiselect("Schema", options=sorted(df_results['SCHEMA_NAME'].unique()), default=[])
            
            with col3:
                filter_table = st.multiselect("Table", options=sorted(df_results['TABLE_NAME'].unique()), default=[])
            
            with col4:
                # Match score filter
                score_range = st.slider(
                    "Match Score Range",
                    min_value=0,
                    max_value=100,
                    value=(0, 100),
                    help="Filter by match score percentage"
                )
            
            # Apply filters
            filtered_df = df_results.copy()
            if filter_domain:
                filtered_df = filtered_df[filtered_df['MATCHED_DOMAIN'].isin(filter_domain)]
            if filter_tag:
                filtered_df = filtered_df[filtered_df['MATCHED_TAG'].isin(filter_tag)]
            if filter_pii:
                filtered_df = filtered_df[filtered_df['MATCHED_IS_PII'].isin(filter_pii)]
            if filter_database:
                filtered_df = filtered_df[filtered_df['DATABASE_NAME'].isin(filter_database)]
            if filter_schema:
                filtered_df = filtered_df[filtered_df['SCHEMA_NAME'].isin(filter_schema)]
            if filter_table:
                filtered_df = filtered_df[filtered_df['TABLE_NAME'].isin(filter_table)]
            if filter_method and 'MATCH_METHOD' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['MATCH_METHOD'].isin(filter_method)]
            # Apply score range filter
            if 'MATCH_SCORE' in filtered_df.columns:
                filtered_df = filtered_df[
                    (filtered_df['MATCH_SCORE'] >= score_range[0]) & 
                    (filtered_df['MATCH_SCORE'] <= score_range[1])
                ]
            
            st.markdown("---")
            st.info(f"Showing **{len(filtered_df)}** of **{len(df_results)}** scan results")
            
            # =========================================================
            # QUESTIONABLE MATCHES SECTION (FALSE POSITIVE DETECTION)
            # =========================================================
            st.markdown("---")
            st.markdown("### ‚ö†Ô∏è Questionable Matches (Potential False Positives)")
            
            # Detect questionable matches based on multiple criteria
            questionable_df = filtered_df.copy()
            
            # Criteria for questionable matches:
            questionable_conditions = []
            
            # 1. Generic single-word patterns
            if 'PATTERN_VALUE' in questionable_df.columns:
                generic_words = ['TYPE', 'DATE', 'RATE', 'CODE', 'NAME', 'NUMBER', 'STATUS', 
                               'VALUE', 'AMOUNT', 'ID', 'PERCENT', 'TOTAL', 'AGE']
                questionable_conditions.append(
                    questionable_df['PATTERN_VALUE'].isin(generic_words)
                )
            
            # 2. Low match scores
            if 'MATCH_SCORE' in questionable_df.columns:
                questionable_conditions.append(
                    questionable_df['MATCH_SCORE'] < 70
                )
            
            # 3. AI flagged as questionable
            if 'MATCH_REASON' in questionable_df.columns:
                questionable_conditions.append(
                    questionable_df['MATCH_REASON'].str.contains('‚ö†Ô∏è|QUESTIONABLE|FALSE POSITIVE', case=False, na=False)
                )
            
            # 4. Short pattern values (likely false positives)
            if 'PATTERN_VALUE' in questionable_df.columns:
                questionable_conditions.append(
                    (questionable_df['PATTERN_TYPE'] == 'CONTAINS') & 
                    (questionable_df['PATTERN_VALUE'].str.len() <= 3)
                )
            
            # 5. Domain mismatch indicators (property/actuarial ‚Üí insurance)
            questionable_conditions.append(
                (questionable_df['TABLE_NAME'].str.contains('PROPERTY|ACTUARIAL|HEATING|BUILDING', case=False, na=False)) &
                (questionable_df['MATCHED_DOMAIN'].isin(['Claims', 'Policy', 'Coverage/Rider']))
            )
            
            # Combine all conditions (OR logic - any condition triggers questionable flag)
            if questionable_conditions:
                questionable_mask = questionable_conditions[0]
                for condition in questionable_conditions[1:]:
                    questionable_mask = questionable_mask | condition
                
                questionable_matches = questionable_df[questionable_mask].copy()
            else:
                questionable_matches = pd.DataFrame()
            
            # Display questionable matches
            if len(questionable_matches) > 0:
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.warning(f"‚ö†Ô∏è Found **{len(questionable_matches)}** questionable matches that may be false positives")
                with col2:
                    if st.button("üóëÔ∏è Delete All Questionable", type="secondary"):
                        try:
                            # Delete questionable matches from database
                            scan_ids = questionable_matches['SCAN_ID'].tolist()
                            scan_ids_str = ','.join([str(x) for x in scan_ids])
                            
                            delete_query = f"""
                            DELETE FROM CDE_SCAN_RESULTS
                            WHERE SCAN_ID IN ({scan_ids_str})
                            """
                            session.sql(delete_query).collect()
                            st.success(f"‚úÖ Deleted {len(questionable_matches)} questionable matches")
                            st.rerun()
                        except Exception as e:
                            st.error(f"Error deleting: {str(e)}")
                
                # Show questionable matches in expandable section
                with st.expander(f"üëÅÔ∏è View {len(questionable_matches)} Questionable Matches", expanded=True):
                    for idx, row in questionable_matches.head(50).iterrows():
                        # Determine why it's questionable
                        reasons = []
                        if 'PATTERN_VALUE' in row and str(row['PATTERN_VALUE']) in ['TYPE', 'DATE', 'RATE', 'CODE', 'NAME', 'NUMBER', 'STATUS', 'VALUE', 'AMOUNT', 'ID', 'AGE']:
                            reasons.append(f"Generic pattern: '{row['PATTERN_VALUE']}'")
                        if 'MATCH_SCORE' in row and row['MATCH_SCORE'] < 70:
                            reasons.append(f"Low score: {row['MATCH_SCORE']:.0f}%")
                        if 'MATCH_REASON' in row and ('‚ö†Ô∏è' in str(row['MATCH_REASON']) or 'QUESTIONABLE' in str(row['MATCH_REASON']).upper()):
                            reasons.append("AI flagged")
                        if 'PATTERN_VALUE' in row and 'PATTERN_TYPE' in row and row['PATTERN_TYPE'] == 'CONTAINS' and len(str(row['PATTERN_VALUE'])) <= 3:
                            reasons.append(f"Short: '{row['PATTERN_VALUE']}'")
                        if 'TABLE_NAME' in row and any(word in str(row['TABLE_NAME']).upper() for word in ['PROPERTY', 'ACTUARIAL', 'HEATING', 'BUILDING']):
                            reasons.append("Domain mismatch")
                        
                        reason_text = " | ".join(reasons) if reasons else "Multiple indicators"
                        
                        col_a, col_b = st.columns([4, 1])
                        with col_a:
                            st.markdown(f"**‚ö†Ô∏è {row['TABLE_NAME']}.{row['COLUMN_NAME']} ‚Üí {row['MATCHED_ATTRIBUTE_LOGICAL_NAME']}**")
                            st.caption(f"üîç {reason_text}")
                        with col_b:
                            if st.button("üóëÔ∏è", key=f"del_{row['SCAN_ID']}", help="Delete this match"):
                                try:
                                    session.sql(f"DELETE FROM CDE_SCAN_RESULTS WHERE SCAN_ID = {row['SCAN_ID']}").collect()
                                    st.success("‚úÖ")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"‚ùå {str(e)[:50]}")
                    
                    if len(questionable_matches) > 50:
                        st.info(f"Showing first 50 of {len(questionable_matches)} questionable matches")
                
                # Download questionable matches for review
                st.download_button(
                    label="üì• Download Questionable Matches",
                    data=questionable_matches.to_csv(index=False),
                    file_name=f"questionable_matches_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            else:
                st.success("‚úÖ No questionable matches detected! All results look good.")
            
            # Display results
            st.markdown("---")
            st.markdown("### üìã All Scan Results")
            
            if len(filtered_df) > 0:
                for idx, row in filtered_df.head(50).iterrows():
                    method_badge = f"ü§ñ {row.get('MATCH_METHOD', 'Pattern')}" if 'MATCH_METHOD' in row else "üìê Pattern"
                    pii_icon = "üî¥ PII" if row['MATCHED_IS_PII'] == 'Y' else "üü¢ Non-PII"
                    model_used = f" ({row.get('AI_MODEL_USED', 'N/A')})" if 'AI_MODEL_USED' in row and pd.notna(row.get('AI_MODEL_USED')) else ""
                    
                    with st.expander(f"{pii_icon} | {method_badge}{model_used} | {row['DATABASE_NAME']}.{row['SCHEMA_NAME']}.{row['TABLE_NAME']}.{row['COLUMN_NAME']}"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write(f"**üè¢ Domain:** {row['MATCHED_DOMAIN']}")
                            st.write(f"**üè∑Ô∏è Tag:** {row['MATCHED_TAG']}")
                            st.write(f"**üìù Attribute:** {row['MATCHED_ATTRIBUTE_LOGICAL_NAME']}")
                            st.write(f"**üíæ Data Type:** {row['DATA_TYPE']}")
                        
                        with col2:
                            st.write(f"**üéØ Match Method:** {row.get('MATCH_METHOD', 'Pattern')}")
                            st.write(f"**üìä Match Score:** {row['MATCH_SCORE']:.0f}%")
                            st.write(f"**ü§ñ AI Model:** {row.get('AI_MODEL_USED', 'N/A')}")
                            st.write(f"**üìÖ Scan Date:** {row['SCAN_DATE']}")
                        
                        st.markdown("**üß† AI-Generated Match Reasoning:**")
                        st.success(row['MATCH_REASON'])
                
                if len(filtered_df) > 50:
                    st.warning(f"Showing first 50 of {len(filtered_df)} results. Use filters to narrow down.")
            
            # Download
            st.markdown("---")
            csv = filtered_df.to_csv(index=False)
            st.download_button(
                label="üì• Download Filtered Results",
                data=csv,
                file_name=f"cde_findings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
            
            # Analysis
            st.markdown("---")
            st.markdown("### üìä Analysis")
            
            tab1, tab2, tab3 = st.tabs(["Domain Breakdown", "Match Methods", "PII Summary"])
            
            with tab1:
                domain_counts = filtered_df.groupby('MATCHED_DOMAIN').size().reset_index(name='Count')
                domain_counts = domain_counts.sort_values('Count', ascending=False)
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.bar_chart(domain_counts.set_index('MATCHED_DOMAIN'))
                with col2:
                    st.dataframe(domain_counts, use_container_width=True)
            
            with tab2:
                if 'MATCH_METHOD' in filtered_df.columns:
                    method_counts = filtered_df.groupby('MATCH_METHOD').size().reset_index(name='Count')
                    st.bar_chart(method_counts.set_index('MATCH_METHOD'))
                else:
                    st.info("Match method data not available")
            
            with tab3:
                pii_summary = filtered_df.groupby(['MATCHED_DOMAIN', 'MATCHED_IS_PII']).size().reset_index(name='Count')
                pii_pivot = pii_summary.pivot(index='MATCHED_DOMAIN', columns='MATCHED_IS_PII', values='Count').fillna(0)
                st.dataframe(pii_pivot, use_container_width=True)
    
    except Exception as e:
        st.error(f"‚ùå Error loading findings: {str(e)}")

# ==================== SCREEN 4: ASK CORTEX AI ====================
elif page == "üí¨ Ask Cortex AI":
    st.markdown('<div class="main-header">üí¨ Ask Cortex AI</div>', unsafe_allow_html=True)
    st.markdown('<span class="ai-badge">ü§ñ NATURAL LANGUAGE Q&A</span>', unsafe_allow_html=True)
    
    st.markdown("""
    Ask questions about your CDE scan results in natural language. Cortex AI will analyze your data and provide insights.
    """)
    
    st.markdown("---")
    
    # Model selector for Q&A
    qa_models = get_available_cortex_models()
    qa_model = st.selectbox(
        "Select AI Model for Q&A",
        qa_models,
        index=qa_models.index('mixtral-8x7b') if 'mixtral-8x7b' in qa_models else 0,
        help="Choose which Cortex model to use for answering questions"
    )
    st.markdown(f'<div class="model-info">{get_model_info(qa_model)}</div>', unsafe_allow_html=True)
    
    # Load context
    try:
        df_results = session.sql("SELECT * FROM CDE_SCAN_RESULTS ORDER BY SCAN_DATE DESC LIMIT 1000").to_pandas()
        df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
        
        context_summary = f"""
        AVAILABLE DATA:
        - Total CDE Definitions: {len(df_ref)}
        - Total Scan Results: {len(df_results)}
        - Databases Scanned: {df_results['DATABASE_NAME'].nunique() if len(df_results) > 0 else 0}
        - PII Elements Found: {len(df_results[df_results['MATCHED_IS_PII'] == 'Y']) if len(df_results) > 0 else 0}
        - Domains: {', '.join(df_ref['DOMAIN'].unique())}
        """
        
        st.info(context_summary)
        
        st.markdown("---")
        st.markdown("### ü§ñ Ask Your Question")
        
        # Example questions
        with st.expander("üìù Example Questions"):
            st.markdown("""
            - Which tables contain the most PII data?
            - What are the most common CDEs found in my databases?
            - How many Social Security Number fields were detected?
            - Which domains have the highest risk data?
            - Show me all financial CDEs found in the PROD database
            - What compliance tags are associated with PII data?
            """)
        
        user_question = st.text_area(
            "Your Question:",
            placeholder="e.g., Which tables contain Social Security Numbers?",
            height=100
        )
        
        if st.button("ü§ñ Ask Cortex AI", type="primary"):
            if user_question:
                with st.spinner(f"ü§ñ Cortex AI ({qa_model}) is thinking..."):
                    # Prepare detailed context
                    if len(df_results) > 0:
                        sample_results = df_results.head(100)[['DATABASE_NAME', 'SCHEMA_NAME', 'TABLE_NAME', 
                                                                'COLUMN_NAME', 'MATCHED_DOMAIN', 'MATCHED_TAG',
                                                                'MATCHED_ATTRIBUTE_LOGICAL_NAME', 'MATCHED_IS_PII']].to_string()
                    else:
                        sample_results = "No scan results available yet."
                    
                    prompt = f"""You are a data governance analyst with access to CDE scan results.
                    
                    CONTEXT:
                    {context_summary}
                    
                    SAMPLE SCAN RESULTS (first 100 records):
                    {sample_results}
                    
                    USER QUESTION: {user_question}
                    
                    Provide a helpful, accurate answer based on the data above. If you need to make assumptions, state them clearly.
                    Be specific with numbers, table names, and column names when possible.
                    Format your response in a clear, structured way.
                    """
                    
                    try:
                        answer = call_cortex(prompt, qa_model)
                        
                        st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                        st.markdown(f"### ü§ñ Cortex AI Response (using {qa_model}):")
                        st.markdown(answer)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                    except Exception as e:
                        st.error(f"Error: {str(e)}")
            else:
                st.warning("Please enter a question")
    
    except Exception as e:
        st.error(f"Error loading data: {str(e)}")

# Footer
st.sidebar.markdown("---")
st.sidebar.markdown("### üìä Statistics")
try:
    ref_count = session.sql("SELECT COUNT(*) as CNT FROM CDE_REFERENCE WHERE IS_ACTIVE = TRUE").collect()[0]['CNT']
    scan_count = session.sql("SELECT COUNT(*) as CNT FROM CDE_SCAN_RESULTS").collect()[0]['CNT']
    st.sidebar.metric("CDE Definitions", ref_count)
    st.sidebar.metric("Scan Results", scan_count)
except:
    pass

st.sidebar.markdown("---")
st.sidebar.caption("ü§ñ Powered by Snowflake Cortex AI")
st.sidebar.caption(f"üìä {len(get_available_cortex_models())} models available")
st.sidebar.caption("Built with ‚ù§Ô∏è for Data Governance")
