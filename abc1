import streamlit as st
import pandas as pd
import snowflake.snowpark as snowpark
from snowflake.snowpark import Session
import snowflake.snowpark.functions as F
from datetime import datetime
import re
import json

# Page configuration
st.set_page_config(
    page_title="CDE Management System (AI-Powered)",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .ai-badge {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 1rem;
        font-size: 0.8rem;
        font-weight: bold;
    }
    .intelligent-section {
        background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%);
        border-left: 4px solid #667eea;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .pattern-section {
        background: linear-gradient(135deg, #f093fb15 0%, #f5576c15 100%);
        border-left: 4px solid #f093fb;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .success-ai {
        background: linear-gradient(135deg, #11998e15 0%, #38ef7d15 100%);
        border-left: 4px solid #11998e;
        padding: 1rem;
        border-radius: 0.5rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
</style>
""", unsafe_allow_html=True)

# Get Snowflake session
@st.cache_resource
def get_session():
    return snowpark.context.get_active_session()

try:
    session = get_session()
except:
    st.error("‚ùå Unable to connect to Snowflake session.")
    st.stop()

# Cortex Helper Function using SQL
def call_cortex(prompt, model='mixtral-8x7b'):
    """Call Cortex AI using SQL function"""
    try:
        # Escape single quotes in prompt
        prompt_clean = prompt.replace("'", "''")
        
        sql = f"""
        SELECT SNOWFLAKE.CORTEX.COMPLETE(
            '{model}',
            '{prompt_clean}'
        ) as response
        """
        
        result = session.sql(sql).collect()
        return result[0]['RESPONSE'] if result else ""
    except Exception as e:
        return f"Error calling Cortex: {str(e)}"

# Exclusion Check Function
def is_excluded_column(column_name):
    """Check if column should be excluded from CDE scanning"""
    try:
        # Try to load exclusion patterns
        df_exclusions = session.table("CDE_EXCLUSION_PATTERNS").filter(F.col("IS_ACTIVE") == True).to_pandas()
        
        column_upper = column_name.upper()
        
        for _, exclusion in df_exclusions.iterrows():
            exclusion_type = exclusion['EXCLUSION_TYPE']
            exclusion_value = exclusion['EXCLUSION_VALUE'].upper()
            
            if exclusion_type == 'EXACT':
                if column_upper == exclusion_value:
                    return True, exclusion['EXCLUSION_REASON']
            
            elif exclusion_type == 'CONTAINS':
                if exclusion_value in column_upper:
                    return True, exclusion['EXCLUSION_REASON']
            
            elif exclusion_type == 'STARTS_WITH':
                if column_upper.startswith(exclusion_value):
                    return True, exclusion['EXCLUSION_REASON']
            
            elif exclusion_type == 'ENDS_WITH':
                if column_upper.endswith(exclusion_value):
                    return True, exclusion['EXCLUSION_REASON']
        
        return False, None
        
    except Exception as e:
        # If exclusion table doesn't exist, skip exclusion check
        return False, None

# Smart Exclusion with AI (optional - for edge cases)
def ai_should_exclude_column(column_name, table_name, data_type):
    """Use AI to determine if column is technical/audit (fallback)"""
    prompt = f"""Is this database column a technical/audit/system column that should be excluded from business data analysis?

Column: {column_name}
Table: {table_name}
Type: {data_type}

Common technical columns: created_at, updated_by, record_id, version, etl_batch_id, hash, checksum, etc.

Answer ONLY: YES or NO"""
    
    try:
        result = call_cortex(prompt, model)
        return 'YES' in result.upper()
    except:
        return False

# Cortex AI Functions
def generate_pattern_suggestions(attribute_name, domain):
    """Generate intelligent pattern suggestions using Cortex"""
    prompt = f"""You are a data governance expert. Given this data element:
    - Attribute Name: {attribute_name}
    - Domain: {domain}
    
    Generate 8 common database column name variations that might exist in real databases.
    Consider: abbreviations, prefixes, suffixes, underscores, common aliases.
    
    Return ONLY a JSON array of strings (no explanation):
    ["PATTERN1", "PATTERN2", ...]
    """
    
    try:
        result = call_cortex(prompt, 'mixtral-8x7b')
        # Extract JSON array from response
        result = result.strip()
        if '```' in result:
            result = result.split('```')[1].replace('json', '').strip()
        patterns = json.loads(result)
        return patterns if isinstance(patterns, list) else []
    except:
        return []

def generate_definition(attribute_name, domain, tag):
    """Generate professional definition using Cortex"""
    prompt = f"""You are a data dictionary expert. Write a clear, professional definition for:
    - Attribute: {attribute_name}
    - Domain: {domain}
    - Tag: {tag}
    
    Requirements:
    - 2-3 sentences maximum
    - Professional tone
    - Include: what it is, why it matters, typical usage
    - No bullet points
    
    Return ONLY the definition text (no labels or formatting).
    """
    
    try:
        result = call_cortex(prompt, 'mixtral-8x7b')
        return result.strip()
    except Exception as e:
        return f"Error generating definition: {str(e)}"

def semantic_column_match(column_name, cde_list, context="", model='mixtral-8x7b'):
    """Find semantic matches using Cortex with strict validation"""
    cde_sample = cde_list[:20]  # Limit for token size
    
    prompt = f"""You are a STRICT data matching expert. Avoid false positives.
    
    Column to match: "{column_name}"
    Context: {context}
    
    Available CDEs:
    {chr(10).join([f"- {cde}" for cde in cde_sample])}
    
    STRICT MATCHING RULES:
    - Only match if column and CDE have SAME semantic meaning
    - Generic word overlap is NOT enough (HEATING_TYPE ‚â† CLAIM_TYPE)
    - Domain must match (actuarial ‚â† claims)
    - Context matters (EFFECTIVE_DATE ‚â† CLAIM_DATE_OF_LOSS)
    
    WRONG matches to avoid:
    - Different rate types (LAPSE_RATE ‚â† COMMISSION_RATE)
    - Different date types (CONTRACT_DATE ‚â† LOSS_DATE)
    - Different domains (property columns ‚â† insurance CDEs)
    
    Return ONLY:
    - The matched CDE name if TRULY similar (confidence > 85%)
    - "NONE" if no strong match
    
    No explanation, just the answer.
    """
    
    try:
        result = call_cortex(prompt, model)
        result = result.strip().strip('"').strip("'")
        return result if result != "NONE" else None
    except:
        return None

def generate_intelligent_reasoning(column_name, table_name, matched_cde, definition, data_type, is_pii, model='mixtral-8x7b'):
    """Generate intelligent match reasoning using Cortex with strict validation"""
    prompt = f"""You are a strict data governance analyst. Critically evaluate this CDE match:
    
    MATCH DETAILS:
    - Column: {column_name} (Type: {data_type})
    - Table: {table_name}
    - Matched CDE: {matched_cde}
    - Is PII: {is_pii}
    - Definition: {definition}
    
    CRITICAL EVALUATION:
    First, determine if this is a VALID match or FALSE POSITIVE.
    
    FALSE POSITIVE indicators:
    - Generic words matching (e.g., HEATING_TYPE ‚Üí CLAIM TYPE is WRONG)
    - Domain mismatch (e.g., property data ‚Üí claims domain is WRONG)
    - Context mismatch (e.g., EFFECTIVE_DATE in actuarial ‚Üí CLAIM DATE is WRONG)
    - Similar but different meaning (e.g., LAPSE_RATE ‚Üí COMMISSION_RATE is WRONG)
    
    If FALSE POSITIVE, start with: "‚ö†Ô∏è QUESTIONABLE MATCH"
    If VALID match, provide:
    1. Why this is a match (1 sentence)
    2. Data sensitivity (1 sentence)
    3. Recommended action (1 sentence)
    
    Return single paragraph, professional tone, max 150 words.
    """
    
    try:
        result = call_cortex(prompt, model)
        return result.strip()
    except Exception as e:
        return f"Standard match based on pattern matching. {definition[:100]}"

def validate_match_quality(column_name, table_name, matched_cde, definition, model='mixtral-8x7b'):
    """AI validation of match quality"""
    prompt = f"""You are a data quality validator.
    
    MATCH TO VALIDATE:
    - Column: {column_name} in table {table_name}
    - Matched CDE: {matched_cde}
    - CDE Definition: {definition}
    
    Is this a TRUE MATCH or FALSE POSITIVE?
    
    Consider:
    - Semantic alignment
    - Context appropriateness
    - Definition relevance
    
    Return ONLY: TRUE or FALSE (nothing else)
    """
    
    try:
        result = call_cortex(prompt, 'mistral-7b')
        return 'TRUE' in result.upper()
    except:
        return True  # Default to true if AI fails

def ai_classify_column(column_name, table_name, data_type):
    """AI-powered column classification"""
    prompt = f"""You are a data classification expert.
    
    Classify this database column:
    - Column: {column_name}
    - Table: {table_name}
    - Data Type: {data_type}
    
    Provide:
    1. Likely Domain (Claims, Coverage, Financial, etc.)
    2. Likely Tag (Event Details, Financial Metrics, etc.)
    3. PII Status (Y or N)
    4. Confidence (0-100)
    
    Return as JSON:
    {{"domain": "...", "tag": "...", "is_pii": "Y/N", "confidence": 85}}
    """
    
    try:
        result = call_cortex(prompt, 'mixtral-8x7b')
        if '```' in result:
            result = result.split('```')[1].replace('json', '').strip()
        classification = json.loads(result)
        return classification
    except:
        return {"domain": "Unknown", "tag": "Unknown", "is_pii": "N", "confidence": 0}

# Helper function to generate unique scan run ID
def generate_scan_run_id():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    return f"SCAN_{timestamp}"

# Helper function to match patterns
def match_pattern(column_name, pattern_type, pattern_value):
    """Check if a column name matches a pattern with improved accuracy"""
    column_upper = column_name.upper()
    pattern_upper = pattern_value.upper()
    
    if pattern_type == 'EXACT':
        return column_upper == pattern_upper
    
    elif pattern_type == 'CONTAINS':
        # Improved CONTAINS logic to avoid false positives
        
        # If pattern is very short (1-2 chars), require exact word match
        if len(pattern_upper) <= 2:
            # Use word boundary matching for short patterns
            words = column_upper.replace('_', ' ').split()
            return pattern_upper in words
        
        # For patterns 3 chars or longer, check if it's a meaningful substring
        if pattern_upper in column_upper:
            # Additional validation: avoid matching if pattern is just part of a longer word
            # Example: Don't match "AGE" in "AGENT_CODE"
            
            # Find the position of the match
            idx = column_upper.find(pattern_upper)
            
            # Check if pattern is surrounded by word boundaries (_, space, or string edges)
            is_word_boundary_before = (idx == 0 or column_upper[idx - 1] in ['_', ' ', '-'])
            is_word_boundary_after = (idx + len(pattern_upper) >= len(column_upper) or 
                                     column_upper[idx + len(pattern_upper)] in ['_', ' ', '-'])
            
            # Pattern must be at word boundaries OR be 4+ characters long
            if is_word_boundary_before and is_word_boundary_after:
                return True
            elif len(pattern_upper) >= 4:  # Longer patterns can match within words
                return True
            else:
                return False
        
        return False
    
    elif pattern_type == 'STARTS_WITH':
        return column_upper.startswith(pattern_upper)
    
    elif pattern_type == 'ENDS_WITH':
        return column_upper.endswith(pattern_upper)
    
    elif pattern_type == 'REGEX':
        try:
            return bool(re.search(pattern_upper, column_upper))
        except:
            return False
    
    return False

# Sidebar navigation
st.sidebar.markdown("# ü§ñ CDE Management")
st.sidebar.markdown("*Powered by Snowflake Cortex AI*")
st.sidebar.markdown("---")

page = st.sidebar.radio(
    "Navigate to:",
    [
        "üìã Reference Data Management",
        "üîç CDE Scan (Intelligent)",
        "üìä CDE Findings & Analysis",
        "üí¨ Ask Cortex AI"
    ],
    key="navigation"
)

st.sidebar.markdown("---")
st.sidebar.markdown("### üéØ AI Features")
st.sidebar.info("""
‚ú® **AI-Powered Features:**
- ü§ñ Pattern Suggestions
- ‚úçÔ∏è Auto Definitions
- üîç Semantic Matching
- üß† Intelligent Reasoning
- ‚úÖ Match Validation
- üí¨ Natural Language Q&A
""")

# ==================== SCREEN 1: REFERENCE DATA MANAGEMENT ====================
if page == "üìã Reference Data Management":
    st.markdown('<div class="main-header">üìã CDE Reference Data Management</div>', unsafe_allow_html=True)
    st.markdown('<span class="ai-badge">ü§ñ AI-ENHANCED</span>', unsafe_allow_html=True)
    
    # Create reference table if not exists
    try:
        session.sql("""
            CREATE TABLE IF NOT EXISTS CDE_REFERENCE (
                CDE_ID NUMBER AUTOINCREMENT,
                DOMAIN VARCHAR(200),
                TAG VARCHAR(200),
                ATTRIBUTE_LOGICAL_NAME VARCHAR(500),
                IS_PII VARCHAR(1),
                DEFINITION TEXT,
                CREATED_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
                CREATED_BY VARCHAR(100) DEFAULT CURRENT_USER(),
                UPDATED_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
                UPDATED_BY VARCHAR(100) DEFAULT CURRENT_USER(),
                IS_ACTIVE BOOLEAN DEFAULT TRUE,
                PRIMARY KEY (CDE_ID)
            )
        """).collect()
    except Exception as e:
        st.error(f"Error ensuring table exists: {str(e)}")
    
    # Tabs for different operations
    tab1, tab2, tab3, tab4 = st.tabs(["üìä View All", "‚ûï Add New (AI-Enhanced)", "‚úèÔ∏è Edit", "üóëÔ∏è Delete"])
    
    # TAB 1: View All (unchanged - keeping it clean)
    with tab1:
        st.markdown("### Current CDE Reference Data")
        
        try:
            df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
            
            if len(df_ref) > 0:
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Total CDEs", len(df_ref))
                with col2:
                    st.metric("Unique Domains", df_ref['DOMAIN'].nunique())
                with col3:
                    st.metric("PII Elements", len(df_ref[df_ref['IS_PII'] == 'Y']))
                with col4:
                    st.metric("Unique Tags", df_ref['TAG'].nunique())
                
                st.markdown("---")
                
                # Filters
                col1, col2, col3 = st.columns(3)
                with col1:
                    filter_domain = st.multiselect(
                        "Filter by Domain",
                        options=sorted(df_ref['DOMAIN'].dropna().unique().tolist()),
                        default=[]
                    )
                with col2:
                    filter_tag = st.multiselect(
                        "Filter by Tag",
                        options=sorted(df_ref['TAG'].dropna().unique().tolist()),
                        default=[]
                    )
                with col3:
                    filter_pii = st.selectbox("Filter by PII", options=["All", "Y", "N"])
                
                # Apply filters
                filtered_df = df_ref.copy()
                if filter_domain:
                    filtered_df = filtered_df[filtered_df['DOMAIN'].isin(filter_domain)]
                if filter_tag:
                    filtered_df = filtered_df[filtered_df['TAG'].isin(filter_tag)]
                if filter_pii != "All":
                    filtered_df = filtered_df[filtered_df['IS_PII'] == filter_pii]
                
                st.info(f"Showing {len(filtered_df)} of {len(df_ref)} records")
                
                st.dataframe(
                    filtered_df[['CDE_ID', 'DOMAIN', 'TAG', 'ATTRIBUTE_LOGICAL_NAME', 'IS_PII', 'DEFINITION']],
                    use_container_width=True,
                    height=500
                )
                
                csv = filtered_df.to_csv(index=False)
                st.download_button(
                    label="üì• Download as CSV",
                    data=csv,
                    file_name=f"cde_reference_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
                
            else:
                st.warning("‚ö†Ô∏è No reference data found. Please add CDE definitions.")
        except Exception as e:
            st.error(f"Error loading reference data: {str(e)}")
    
    # TAB 2: Add New - AI ENHANCED
    with tab2:
        st.markdown("### Add New CDE Definition")
        st.markdown('<span class="ai-badge">ü§ñ AI-POWERED</span>', unsafe_allow_html=True)
        
        # Manual Entry Section
        st.markdown('<div class="pattern-section">', unsafe_allow_html=True)
        st.markdown("#### üìù Manual Entry")
        
        with st.form("add_cde_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                add_domain = st.text_input("Domain *", placeholder="e.g., Claims, Coverage/Rider")
                add_tag = st.text_input("Tag *", placeholder="e.g., Event Details, Financial Metrics")
                add_attr_name = st.text_input("Attribute Logical Name *", placeholder="e.g., CLAIM_DATE_OF_LOSS")
            
            with col2:
                add_is_pii = st.selectbox("Is PII? *", options=["N", "Y"])
                add_definition = st.text_area("Definition *", placeholder="Detailed description", height=120)
            
            submit_add = st.form_submit_button("‚ûï Add CDE", type="primary")
            
            if submit_add:
                if not add_domain or not add_tag or not add_attr_name or not add_definition:
                    st.error("‚ùå Please fill in all required fields (*)")
                else:
                    try:
                        domain_clean = add_domain.replace("'", "''")
                        tag_clean = add_tag.replace("'", "''")
                        attr_clean = add_attr_name.replace("'", "''")
                        def_clean = add_definition.replace("'", "''")
                        
                        insert_query = f"""
                        INSERT INTO CDE_REFERENCE (DOMAIN, TAG, ATTRIBUTE_LOGICAL_NAME, IS_PII, DEFINITION)
                        VALUES ('{domain_clean}', '{tag_clean}', '{attr_clean}', '{add_is_pii}', '{def_clean}')
                        """
                        session.sql(insert_query).collect()
                        st.success(f"‚úÖ Successfully added CDE: **{add_attr_name}**")
                        st.balloons()
                        st.rerun()
                    except Exception as e:
                        st.error(f"‚ùå Error adding CDE: {str(e)}")
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # AI Assistant Section
        st.markdown('<div class="intelligent-section">', unsafe_allow_html=True)
        st.markdown("#### ü§ñ AI Assistant")
        st.markdown("*Use Cortex AI to help create your CDE definition*")
        
        col1, col2 = st.columns(2)
        
        with col1:
            ai_attr_name = st.text_input("Attribute Name", key="ai_attr", placeholder="e.g., CUSTOMER_SSN")
            ai_domain = st.text_input("Domain", key="ai_domain", placeholder="e.g., New Business")
        
        with col2:
            ai_tag = st.text_input("Tag", key="ai_tag", placeholder="e.g., Applicant Info")
        
        st.markdown("---")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ü§ñ Generate Pattern Suggestions", type="secondary", use_container_width=True):
                if ai_attr_name and ai_domain:
                    with st.spinner("ü§ñ AI is thinking..."):
                        patterns = generate_pattern_suggestions(ai_attr_name, ai_domain)
                        if patterns:
                            st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                            st.markdown("**üí° AI-Generated Pattern Suggestions:**")
                            st.code(", ".join(patterns))
                            st.markdown("*Use these to create pattern rules in CDE_PATTERN_RULES table*")
                            st.markdown('</div>', unsafe_allow_html=True)
                        else:
                            st.warning("Could not generate patterns")
                else:
                    st.warning("Please enter Attribute Name and Domain")
        
        with col2:
            if st.button("‚úçÔ∏è Generate Definition", type="secondary", use_container_width=True):
                if ai_attr_name and ai_domain:
                    with st.spinner("ü§ñ AI is writing..."):
                        definition = generate_definition(ai_attr_name, ai_domain, ai_tag or "General")
                        if definition:
                            st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                            st.markdown("**üìù AI-Generated Definition:**")
                            st.info(definition)
                            st.markdown('</div>', unsafe_allow_html=True)
                else:
                    st.warning("Please enter Attribute Name and Domain")
        
        with col3:
            if st.button("üéØ Suggest Classification", type="secondary", use_container_width=True):
                if ai_attr_name:
                    with st.spinner("ü§ñ AI is analyzing..."):
                        classification = ai_classify_column(ai_attr_name, "N/A", "VARCHAR")
                        st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                        st.markdown("**üéØ AI Classification:**")
                        st.write(f"**Domain:** {classification.get('domain', 'Unknown')}")
                        st.write(f"**Tag:** {classification.get('tag', 'Unknown')}")
                        st.write(f"**PII:** {classification.get('is_pii', 'N')}")
                        st.write(f"**Confidence:** {classification.get('confidence', 0)}%")
                        st.markdown('</div>', unsafe_allow_html=True)
                else:
                    st.warning("Please enter Attribute Name")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # TAB 3 & 4: Edit and Delete (keeping simple - no AI needed here)
    with tab3:
        st.markdown("### Edit Existing CDE Definition")
        
        try:
            df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
            
            if len(df_ref) > 0:
                cde_options = df_ref.apply(
                    lambda x: f"{x['CDE_ID']} - {x['DOMAIN']} - {x['ATTRIBUTE_LOGICAL_NAME']}", 
                    axis=1
                ).tolist()
                
                selected_cde = st.selectbox("Select CDE to Edit", options=cde_options)
                
                if selected_cde:
                    cde_id = int(selected_cde.split(" - ")[0])
                    current_data = df_ref[df_ref['CDE_ID'] == cde_id].iloc[0]
                    
                    with st.form("edit_cde_form"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            edit_domain = st.text_input("Domain *", value=current_data['DOMAIN'])
                            edit_tag = st.text_input("Tag *", value=current_data['TAG'])
                            edit_attr_name = st.text_input("Attribute Logical Name *", value=current_data['ATTRIBUTE_LOGICAL_NAME'])
                        
                        with col2:
                            edit_is_pii = st.selectbox("Is PII? *", options=["Y", "N"], index=0 if current_data['IS_PII'] == 'Y' else 1)
                            edit_definition = st.text_area("Definition *", value=current_data['DEFINITION'] if pd.notna(current_data['DEFINITION']) else "", height=120)
                        
                        submit_edit = st.form_submit_button("üíæ Update", type="primary")
                        
                        if submit_edit:
                            try:
                                domain_clean = edit_domain.replace("'", "''")
                                tag_clean = edit_tag.replace("'", "''")
                                attr_clean = edit_attr_name.replace("'", "''")
                                def_clean = edit_definition.replace("'", "''")
                                
                                update_query = f"""
                                UPDATE CDE_REFERENCE SET
                                    DOMAIN = '{domain_clean}',
                                    TAG = '{tag_clean}',
                                    ATTRIBUTE_LOGICAL_NAME = '{attr_clean}',
                                    IS_PII = '{edit_is_pii}',
                                    DEFINITION = '{def_clean}',
                                    UPDATED_DATE = CURRENT_TIMESTAMP(),
                                    UPDATED_BY = CURRENT_USER()
                                WHERE CDE_ID = {cde_id}
                                """
                                session.sql(update_query).collect()
                                st.success(f"‚úÖ Successfully updated CDE ID {cde_id}")
                                st.rerun()
                            except Exception as e:
                                st.error(f"‚ùå Error updating CDE: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è No CDE definitions available to edit.")
        except Exception as e:
            st.error(f"‚ùå Error loading data: {str(e)}")
    
    with tab4:
        st.markdown("### Delete CDE Definition")
        st.warning("‚ö†Ô∏è This will soft-delete the record (set IS_ACTIVE = FALSE)")
        
        try:
            df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
            
            if len(df_ref) > 0:
                cde_options = df_ref.apply(
                    lambda x: f"{x['CDE_ID']} - {x['DOMAIN']} - {x['ATTRIBUTE_LOGICAL_NAME']}", 
                    axis=1
                ).tolist()
                
                selected_delete = st.selectbox("Select CDE to Delete", options=cde_options, key="delete_select")
                
                if selected_delete:
                    cde_id = int(selected_delete.split(" - ")[0])
                    current_data = df_ref[df_ref['CDE_ID'] == cde_id].iloc[0]
                    
                    st.markdown("**Record to Delete:**")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**Domain:** {current_data['DOMAIN']}")
                        st.write(f"**Tag:** {current_data['TAG']}")
                    with col2:
                        st.write(f"**Attribute:** {current_data['ATTRIBUTE_LOGICAL_NAME']}")
                        st.write(f"**Is PII:** {current_data['IS_PII']}")
                    
                    if st.button("üóëÔ∏è Confirm Delete", type="primary"):
                        try:
                            delete_query = f"""
                            UPDATE CDE_REFERENCE 
                            SET IS_ACTIVE = FALSE, UPDATED_DATE = CURRENT_TIMESTAMP(), UPDATED_BY = CURRENT_USER()
                            WHERE CDE_ID = {cde_id}
                            """
                            session.sql(delete_query).collect()
                            st.success(f"‚úÖ CDE ID {cde_id} deleted")
                            st.rerun()
                        except Exception as e:
                            st.error(f"‚ùå Error: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è No CDE definitions available.")
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")

# ==================== SCREEN 2: CDE SCAN (INTELLIGENT) ====================
elif page == "üîç CDE Scan (Intelligent)":
    st.markdown('<div class="main-header">üîç Intelligent CDE Scan</div>', unsafe_allow_html=True)
    st.markdown('<span class="ai-badge">ü§ñ AI-POWERED MATCHING</span>', unsafe_allow_html=True)
    
    # Create scan results table
    try:
        session.sql("""
            CREATE TABLE IF NOT EXISTS CDE_SCAN_RESULTS (
                SCAN_ID NUMBER AUTOINCREMENT,
                SCAN_RUN_ID VARCHAR(100),
                SCAN_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
                SCAN_USER VARCHAR(100) DEFAULT CURRENT_USER(),
                DATABASE_NAME VARCHAR(200),
                SCHEMA_NAME VARCHAR(200),
                TABLE_NAME VARCHAR(200),
                COLUMN_NAME VARCHAR(200),
                DATA_TYPE VARCHAR(100),
                MATCHED_CDE_ID NUMBER,
                MATCHED_DOMAIN VARCHAR(200),
                MATCHED_TAG VARCHAR(200),
                MATCHED_ATTRIBUTE_LOGICAL_NAME VARCHAR(500),
                MATCHED_IS_PII VARCHAR(1),
                MATCHED_DEFINITION TEXT,
                PATTERN_ID NUMBER,
                PATTERN_TYPE VARCHAR(50),
                PATTERN_VALUE VARCHAR(500),
                MATCH_SCORE NUMBER(5,2),
                MATCH_REASON VARCHAR(2000),
                MATCH_METHOD VARCHAR(50),
                AI_VALIDATED BOOLEAN,
                IS_REVIEWED BOOLEAN DEFAULT FALSE,
                REVIEW_STATUS VARCHAR(50),
                REVIEW_NOTES TEXT,
                REVIEWED_BY VARCHAR(100),
                REVIEWED_DATE TIMESTAMP_NTZ,
                PRIMARY KEY (SCAN_ID)
            )
        """).collect()
    except Exception as e:
        st.error(f"Error: {str(e)}")
    
    st.markdown("---")
    
    # Scan Configuration
    st.markdown("### ‚öôÔ∏è Scan Configuration")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        scan_mode = st.selectbox(
            "Scan Mode",
            ["Pattern + AI", "Pattern Only", "AI Only"],
            help="Pattern+AI: Best accuracy (slower) | Pattern Only: Fast | AI Only: Experimental"
        )
    
    with col2:
        # Snowflake Cortex AI available models
        # These are the models available in Snowflake Cortex (as of 2024)
        model_list = [
            'snowflake-arctic',           # Snowflake's own model
            'reka-core',                  # Reka AI
            'reka-flash',                 # Reka AI (faster)
            'mistral-large',              # Mistral AI (most capable)
            'mistral-7b',                 # Mistral AI (small, fast)
            'mixtral-8x7b',               # Mistral AI (balanced)
            'llama3-8b',                  # Meta
            'llama3-70b',                 # Meta (large)
            'llama3.1-8b',                # Meta (latest small)
            'llama3.1-70b',               # Meta (latest large)
            'llama3.1-405b',              # Meta (largest)
            'llama3.2-1b',                # Meta (tiny, fast)
            'llama3.2-3b',                # Meta (small, fast)
            'gemma-7b',                   # Google
            'mistral-large2'              # Mistral AI (latest large)
        ]
        
        selected_llm = st.selectbox(
            "LLM Model for AI Matching",
            model_list,
            index=5 if 'mixtral-8x7b' in model_list else 0,
            help="""Select Cortex AI model for semantic matching:
            ‚Ä¢ mixtral-8x7b: Best balance (recommended)
            ‚Ä¢ mistral-large/large2: Most accurate
            ‚Ä¢ llama3.1-70b/405b: Very accurate, slower
            ‚Ä¢ reka-flash: Fast alternative
            ‚Ä¢ mistral-7b/llama3-8b: Fastest, good for testing"""
        )
    
    with col3:
        ai_confidence = st.slider(
            "AI Confidence Threshold",
            min_value=70,
            max_value=95,
            value=85,
            step=5,
            help="Minimum confidence for AI matches (higher = fewer but more accurate matches)"
        )
    
    st.markdown("---")
    
    # Database and Schema Selection
    st.markdown("### üéØ Select Scan Scope")
    
    col1, col2 = st.columns(2)
    
    with col1:
        try:
            databases = session.sql("SHOW DATABASES").collect()
            db_list = [row['name'] for row in databases]
            selected_db = st.selectbox("Select Database *", db_list, key="scan_db")
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")
            selected_db = None
    
    with col2:
        if selected_db:
            try:
                schemas = session.sql(f"SHOW SCHEMAS IN DATABASE {selected_db}").collect()
                schema_list = [row['name'] for row in schemas]
                selected_schema = st.selectbox("Select Schema *", schema_list, key="scan_schema")
            except Exception as e:
                st.error(f"‚ùå Error: {str(e)}")
                selected_schema = None
        else:
            selected_schema = None
    
    if selected_db and selected_schema:
        st.success(f"üìç **Scan Scope:** `{selected_db}.{selected_schema}` | **Mode:** {scan_mode}")
        
        st.markdown("---")
        
        col1, col2 = st.columns([1, 1])
        with col1:
            start_scan = st.button("ü§ñ Start Intelligent Scan", type="primary", use_container_width=True)
        with col2:
            preview_tables = st.button("üëÅÔ∏è Preview Tables", use_container_width=True)
        
        if preview_tables:
            try:
                preview_query = f"""
                SELECT TABLE_NAME, COUNT(*) as COLUMN_COUNT
                FROM {selected_db}.INFORMATION_SCHEMA.COLUMNS
                WHERE TABLE_SCHEMA = '{selected_schema}'
                GROUP BY TABLE_NAME
                ORDER BY TABLE_NAME
                """
                df_preview = session.sql(preview_query).to_pandas()
                
                if len(df_preview) > 0:
                    st.info(f"üìä Found **{len(df_preview)}** tables with **{df_preview['COLUMN_COUNT'].sum()}** columns")
                    st.dataframe(df_preview, use_container_width=True, height=300)
                else:
                    st.warning(f"No tables found")
            except Exception as e:
                st.error(f"Error: {str(e)}")
        
        if start_scan:
            scan_run_id = generate_scan_run_id()
            
            with st.spinner(f"ü§ñ {'Intelligent' if 'AI' in scan_mode else 'Pattern'} scanning in progress..."):
                try:
                    # Get columns
                    columns_query = f"""
                    SELECT TABLE_CATALOG as DATABASE_NAME, TABLE_SCHEMA as SCHEMA_NAME,
                           TABLE_NAME, COLUMN_NAME, DATA_TYPE
                    FROM {selected_db}.INFORMATION_SCHEMA.COLUMNS
                    WHERE TABLE_SCHEMA = '{selected_schema}'
                    ORDER BY TABLE_NAME, ORDINAL_POSITION
                    """
                    
                    df_columns = session.sql(columns_query).to_pandas()
                    
                    if len(df_columns) == 0:
                        st.warning(f"‚ö†Ô∏è No tables found")
                    else:
                        st.info(f"üìä Scanning **{len(df_columns)}** columns across **{df_columns['TABLE_NAME'].nunique()}** tables")
                        
                        df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
                        
                        if len(df_ref) == 0:
                            st.error("‚ùå No CDE reference patterns found")
                        else:
                            # Get pattern rules
                            try:
                                df_patterns = session.table("CDE_PATTERN_RULES").filter(F.col("IS_ACTIVE") == True).to_pandas()
                            except:
                                df_patterns = pd.DataFrame({
                                    'PATTERN_ID': range(len(df_ref)),
                                    'CDE_ID': df_ref['CDE_ID'],
                                    'PATTERN_TYPE': 'EXACT',
                                    'PATTERN_VALUE': df_ref['ATTRIBUTE_LOGICAL_NAME'],
                                    'PATTERN_PRIORITY': 10
                                })
                            
                            matches = []
                            excluded_columns = []
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            # Prepare CDE list for semantic matching
                            cde_list = df_ref['ATTRIBUTE_LOGICAL_NAME'].tolist()
                            
                            total_columns = len(df_columns)
                            ai_matches_count = 0
                            pattern_matches_count = 0
                            excluded_count = 0
                            
                            for idx, col_row in df_columns.iterrows():
                                progress_bar.progress((idx + 1) / total_columns)
                                status_text.text(f"Scanning {idx + 1}/{total_columns}: {col_row['COLUMN_NAME']}")
                                
                                column_name = col_row['COLUMN_NAME']
                                
                                # ========================================
                                # CHECK EXCLUSION LIST FIRST
                                # ========================================
                                is_excluded, exclusion_reason = is_excluded_column(column_name)
                                
                                if is_excluded:
                                    excluded_count += 1
                                    excluded_columns.append({
                                        'COLUMN_NAME': column_name,
                                        'TABLE_NAME': col_row['TABLE_NAME'],
                                        'REASON': exclusion_reason
                                    })
                                    continue  # Skip this column
                                
                                pattern_matched = False
                                
                                # PATTERN MATCHING (if enabled)
                                if scan_mode in ["Pattern + AI", "Pattern Only"]:
                                    for _, pattern_row in df_patterns.iterrows():
                                        if match_pattern(column_name, pattern_row['PATTERN_TYPE'], pattern_row['PATTERN_VALUE']):
                                            cde_data = df_ref[df_ref['CDE_ID'] == pattern_row['CDE_ID']].iloc[0]
                                            
                                            match_score = 100.0 if pattern_row['PATTERN_TYPE'] == 'EXACT' else 80.0
                                            
                                            # Use AI for reasoning if in AI mode
                                            if scan_mode == "Pattern + AI":
                                                match_reason = generate_intelligent_reasoning(
                                                    column_name, col_row['TABLE_NAME'], 
                                                    cde_data['ATTRIBUTE_LOGICAL_NAME'],
                                                    cde_data['DEFINITION'],
                                                    col_row['DATA_TYPE'],
                                                    cde_data['IS_PII'],
                                                    selected_llm
                                                )
                                            else:
                                                match_reason = f"Pattern match: {pattern_row['PATTERN_TYPE']} - {cde_data['DEFINITION'][:150]}"
                                            
                                            matches.append({
                                                'SCAN_RUN_ID': scan_run_id,
                                                'DATABASE_NAME': col_row['DATABASE_NAME'],
                                                'SCHEMA_NAME': col_row['SCHEMA_NAME'],
                                                'TABLE_NAME': col_row['TABLE_NAME'],
                                                'COLUMN_NAME': col_row['COLUMN_NAME'],
                                                'DATA_TYPE': col_row['DATA_TYPE'],
                                                'MATCHED_CDE_ID': int(cde_data['CDE_ID']),
                                                'MATCHED_DOMAIN': cde_data['DOMAIN'],
                                                'MATCHED_TAG': cde_data['TAG'],
                                                'MATCHED_ATTRIBUTE_LOGICAL_NAME': cde_data['ATTRIBUTE_LOGICAL_NAME'],
                                                'MATCHED_IS_PII': cde_data['IS_PII'],
                                                'MATCHED_DEFINITION': cde_data['DEFINITION'],
                                                'PATTERN_ID': int(pattern_row['PATTERN_ID']) if 'PATTERN_ID' in pattern_row else None,
                                                'PATTERN_TYPE': pattern_row['PATTERN_TYPE'],
                                                'PATTERN_VALUE': pattern_row['PATTERN_VALUE'],
                                                'MATCH_SCORE': match_score,
                                                'MATCH_REASON': match_reason,
                                                'MATCH_METHOD': 'Pattern',
                                                'AI_VALIDATED': scan_mode == "Pattern + AI"
                                            })
                                            pattern_matched = True
                                            pattern_matches_count += 1
                                            break
                                
                                # AI SEMANTIC MATCHING (if enabled and no pattern match)
                                if not pattern_matched and scan_mode in ["Pattern + AI", "AI Only"]:
                                    context = f"Table: {col_row['TABLE_NAME']}, Type: {col_row['DATA_TYPE']}"
                                    semantic_match_result = semantic_column_match(column_name, cde_list, context, selected_llm)
                                    
                                    if semantic_match_result and semantic_match_result in cde_list:
                                        cde_data = df_ref[df_ref['ATTRIBUTE_LOGICAL_NAME'] == semantic_match_result].iloc[0]
                                        
                                        match_reason = generate_intelligent_reasoning(
                                            column_name, col_row['TABLE_NAME'],
                                            cde_data['ATTRIBUTE_LOGICAL_NAME'],
                                            cde_data['DEFINITION'],
                                            col_row['DATA_TYPE'],
                                            cde_data['IS_PII'],
                                            selected_llm
                                        )
                                        
                                        matches.append({
                                            'SCAN_RUN_ID': scan_run_id,
                                            'DATABASE_NAME': col_row['DATABASE_NAME'],
                                            'SCHEMA_NAME': col_row['SCHEMA_NAME'],
                                            'TABLE_NAME': col_row['TABLE_NAME'],
                                            'COLUMN_NAME': col_row['COLUMN_NAME'],
                                            'DATA_TYPE': col_row['DATA_TYPE'],
                                            'MATCHED_CDE_ID': int(cde_data['CDE_ID']),
                                            'MATCHED_DOMAIN': cde_data['DOMAIN'],
                                            'MATCHED_TAG': cde_data['TAG'],
                                            'MATCHED_ATTRIBUTE_LOGICAL_NAME': cde_data['ATTRIBUTE_LOGICAL_NAME'],
                                            'MATCHED_IS_PII': cde_data['IS_PII'],
                                            'MATCHED_DEFINITION': cde_data['DEFINITION'],
                                            'PATTERN_ID': None,
                                            'PATTERN_TYPE': 'AI_SEMANTIC',
                                            'PATTERN_VALUE': semantic_match_result,
                                            'MATCH_SCORE': 75.0,
                                            'MATCH_REASON': match_reason,
                                            'MATCH_METHOD': 'AI Semantic',
                                            'AI_VALIDATED': True
                                        })
                                        ai_matches_count += 1
                            
                            progress_bar.empty()
                            status_text.empty()
                            
                            if len(matches) > 0:
                                # Auto-save
                                try:
                                    for match in matches:
                                        def_clean = match['MATCHED_DEFINITION'].replace("'", "''") if match['MATCHED_DEFINITION'] else ''
                                        reason_clean = match['MATCH_REASON'].replace("'", "''")
                                        
                                        insert_query = f"""
                                        INSERT INTO CDE_SCAN_RESULTS (
                                            SCAN_RUN_ID, DATABASE_NAME, SCHEMA_NAME, TABLE_NAME, COLUMN_NAME, DATA_TYPE,
                                            MATCHED_CDE_ID, MATCHED_DOMAIN, MATCHED_TAG, MATCHED_ATTRIBUTE_LOGICAL_NAME,
                                            MATCHED_IS_PII, MATCHED_DEFINITION, PATTERN_ID, PATTERN_TYPE, PATTERN_VALUE,
                                            MATCH_SCORE, MATCH_REASON, MATCH_METHOD, AI_VALIDATED
                                        ) VALUES (
                                            '{match['SCAN_RUN_ID']}', '{match['DATABASE_NAME']}', '{match['SCHEMA_NAME']}',
                                            '{match['TABLE_NAME']}', '{match['COLUMN_NAME']}', '{match['DATA_TYPE']}',
                                            {match['MATCHED_CDE_ID']}, '{match['MATCHED_DOMAIN']}', '{match['MATCHED_TAG']}',
                                            '{match['MATCHED_ATTRIBUTE_LOGICAL_NAME']}', '{match['MATCHED_IS_PII']}', '{def_clean}',
                                            {match['PATTERN_ID'] if match['PATTERN_ID'] else 'NULL'}, '{match['PATTERN_TYPE']}',
                                            '{match['PATTERN_VALUE']}', {match['MATCH_SCORE']}, '{reason_clean}',
                                            '{match['MATCH_METHOD']}', {match['AI_VALIDATED']}
                                        )
                                        """
                                        session.sql(insert_query).collect()
                                    
                                    st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                                    st.markdown(f"### ‚úÖ Scan Complete!")
                                    st.markdown(f"**Total CDEs Found:** {len(matches)}")
                                    st.markdown(f"**Pattern Matches:** {pattern_matches_count} | **AI Matches:** {ai_matches_count}")
                                    st.markdown(f"**Excluded Columns:** {excluded_count} (audit/system columns)")
                                    st.markdown('</div>', unsafe_allow_html=True)
                                    
                                except Exception as save_error:
                                    st.warning(f"‚ö†Ô∏è Found {len(matches)} but save failed: {str(save_error)}")
                                
                                df_matches = pd.DataFrame(matches)
                                
                                # Summary metrics
                                col1, col2, col3, col4, col5 = st.columns(5)
                                with col1:
                                    st.metric("CDEs Found", len(df_matches))
                                with col2:
                                    st.metric("PII Elements", len(df_matches[df_matches['MATCHED_IS_PII'] == 'Y']))
                                with col3:
                                    st.metric("Tables Affected", df_matches['TABLE_NAME'].nunique())
                                with col4:
                                    st.metric("AI Matches", ai_matches_count)
                                with col5:
                                    st.metric("Excluded", excluded_count, help="Audit/system columns filtered out")
                                
                                # Show excluded columns summary
                                if excluded_count > 0:
                                    with st.expander(f"üö´ View {excluded_count} Excluded Columns"):
                                        df_excluded = pd.DataFrame(excluded_columns)
                                        st.dataframe(df_excluded, use_container_width=True)
                                        st.caption("These columns were filtered out as audit/system columns. To modify exclusions, update CDE_EXCLUSION_PATTERNS table.")
                                
                                st.markdown("---")
                                st.markdown("### üìã Scan Results")
                                
                                # Display with method badges
                                for idx, row in df_matches.iterrows():
                                    method_badge = "ü§ñ AI" if row['MATCH_METHOD'] == 'AI Semantic' else "üìê Pattern"
                                    pii_icon = "üî¥" if row['MATCHED_IS_PII'] == 'Y' else "üü¢"
                                    
                                    with st.expander(
                                        f"{pii_icon} {method_badge} | {row['TABLE_NAME']}.{row['COLUMN_NAME']} ‚Üí {row['MATCHED_ATTRIBUTE_LOGICAL_NAME']}"
                                    ):
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.write(f"**Domain:** {row['MATCHED_DOMAIN']}")
                                            st.write(f"**Tag:** {row['MATCHED_TAG']}")
                                            st.write(f"**Data Type:** {row['DATA_TYPE']}")
                                            st.write(f"**Is PII:** {row['MATCHED_IS_PII']}")
                                        with col2:
                                            st.write(f"**Match Method:** {row['MATCH_METHOD']}")
                                            st.write(f"**Pattern Type:** {row['PATTERN_TYPE']}")
                                            st.write(f"**Match Score:** {row['MATCH_SCORE']:.0f}%")
                                            st.write(f"**AI Validated:** {'Yes' if row['AI_VALIDATED'] else 'No'}")
                                        
                                        st.markdown("**üß† Intelligent Match Reasoning:**")
                                        st.info(row['MATCH_REASON'])
                                
                                st.markdown("---")
                                csv = df_matches.to_csv(index=False)
                                st.download_button(
                                    label="üì• Download Results as CSV",
                                    data=csv,
                                    file_name=f"cde_scan_{scan_run_id}.csv",
                                    mime="text/csv"
                                )
                            else:
                                st.warning("‚ö†Ô∏è No CDEs found")
                
                except Exception as e:
                    st.error(f"‚ùå Error during scan: {str(e)}")
                    st.exception(e)

# ==================== SCREEN 3: CDE FINDINGS & ANALYSIS ====================
elif page == "üìä CDE Findings & Analysis":
    st.markdown('<div class="main-header">üìä CDE Findings & Analysis</div>', unsafe_allow_html=True)
    st.markdown('<span class="ai-badge">ü§ñ AI-ENHANCED</span>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("üîÑ Refresh Data", type="secondary"):
            st.rerun()
    
    try:
        df_results = session.sql("SELECT * FROM CDE_SCAN_RESULTS ORDER BY SCAN_DATE DESC").to_pandas()
        
        if len(df_results) == 0:
            st.info("‚ÑπÔ∏è No scan results found. Please run a CDE scan first.")
        else:
            # Summary metrics
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                st.metric("Total CDEs", len(df_results))
            with col2:
                st.metric("PII Elements", len(df_results[df_results['MATCHED_IS_PII'] == 'Y']))
            with col3:
                st.metric("Tables", df_results['TABLE_NAME'].nunique())
            with col4:
                ai_count = len(df_results[df_results['MATCH_METHOD'] == 'AI Semantic']) if 'MATCH_METHOD' in df_results.columns else 0
                st.metric("AI Matches", ai_count)
            with col5:
                avg_score = df_results['MATCH_SCORE'].mean() if 'MATCH_SCORE' in df_results.columns else 0
                st.metric("Avg Score", f"{avg_score:.0f}%")
            
            st.markdown("---")
            
            # Filters
            st.markdown("### üîç Filter Results")
            
            # First row of filters
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                # Get all domains from reference table for complete list
                try:
                    all_domains = session.sql("SELECT DISTINCT DOMAIN FROM CDE_REFERENCE WHERE IS_ACTIVE = TRUE ORDER BY DOMAIN").to_pandas()
                    domain_options = all_domains['DOMAIN'].tolist() if len(all_domains) > 0 else sorted(df_results['MATCHED_DOMAIN'].dropna().unique())
                except:
                    domain_options = sorted(df_results['MATCHED_DOMAIN'].dropna().unique())
                
                filter_domain = st.multiselect("Domain", options=domain_options, default=[])
            
            with col2:
                # Get all tags from reference table
                try:
                    all_tags = session.sql("SELECT DISTINCT TAG FROM CDE_REFERENCE WHERE IS_ACTIVE = TRUE ORDER BY TAG").to_pandas()
                    tag_options = all_tags['TAG'].tolist() if len(all_tags) > 0 else sorted(df_results['MATCHED_TAG'].dropna().unique())
                except:
                    tag_options = sorted(df_results['MATCHED_TAG'].dropna().unique())
                
                filter_tag = st.multiselect("Tag", options=tag_options, default=[])
            
            with col3:
                filter_pii = st.multiselect("PII Status", options=['Y', 'N'], default=[])
            
            with col4:
                if 'MATCH_METHOD' in df_results.columns:
                    filter_method = st.multiselect("Match Method", options=sorted(df_results['MATCH_METHOD'].unique()), default=[])
                else:
                    filter_method = []
            
            # Second row of filters
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                filter_database = st.multiselect("Database", options=sorted(df_results['DATABASE_NAME'].unique()), default=[])
            
            with col2:
                filter_schema = st.multiselect("Schema", options=sorted(df_results['SCHEMA_NAME'].unique()), default=[])
            
            with col3:
                filter_table = st.multiselect("Table", options=sorted(df_results['TABLE_NAME'].unique()), default=[])
            
            with col4:
                # Match score filter
                score_range = st.slider(
                    "Match Score Range",
                    min_value=0,
                    max_value=100,
                    value=(0, 100),
                    help="Filter by match score percentage"
                )
            
            # Apply filters
            filtered_df = df_results.copy()
            if filter_domain:
                filtered_df = filtered_df[filtered_df['MATCHED_DOMAIN'].isin(filter_domain)]
            if filter_tag:
                filtered_df = filtered_df[filtered_df['MATCHED_TAG'].isin(filter_tag)]
            if filter_pii:
                filtered_df = filtered_df[filtered_df['MATCHED_IS_PII'].isin(filter_pii)]
            if filter_database:
                filtered_df = filtered_df[filtered_df['DATABASE_NAME'].isin(filter_database)]
            if filter_schema:
                filtered_df = filtered_df[filtered_df['SCHEMA_NAME'].isin(filter_schema)]
            if filter_table:
                filtered_df = filtered_df[filtered_df['TABLE_NAME'].isin(filter_table)]
            if filter_method and 'MATCH_METHOD' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['MATCH_METHOD'].isin(filter_method)]
            # Apply score range filter
            if 'MATCH_SCORE' in filtered_df.columns:
                filtered_df = filtered_df[
                    (filtered_df['MATCH_SCORE'] >= score_range[0]) & 
                    (filtered_df['MATCH_SCORE'] <= score_range[1])
                ]
            
            st.markdown("---")
            st.info(f"Showing **{len(filtered_df)}** of **{len(df_results)}** scan results")
            
            # =========================================================
            # QUESTIONABLE MATCHES SECTION (FALSE POSITIVE DETECTION)
            # =========================================================
            st.markdown("---")
            st.markdown("### ‚ö†Ô∏è Questionable Matches (Potential False Positives)")
            
            # Detect questionable matches based on multiple criteria
            questionable_df = filtered_df.copy()
            
            # Criteria for questionable matches:
            questionable_conditions = []
            
            # 1. Generic single-word patterns
            if 'PATTERN_VALUE' in questionable_df.columns:
                generic_words = ['TYPE', 'DATE', 'RATE', 'CODE', 'NAME', 'NUMBER', 'STATUS', 
                               'VALUE', 'AMOUNT', 'ID', 'PERCENT', 'TOTAL', 'AGE']
                questionable_conditions.append(
                    questionable_df['PATTERN_VALUE'].isin(generic_words)
                )
            
            # 2. Low match scores
            if 'MATCH_SCORE' in questionable_df.columns:
                questionable_conditions.append(
                    questionable_df['MATCH_SCORE'] < 70
                )
            
            # 3. AI flagged as questionable
            if 'MATCH_REASON' in questionable_df.columns:
                questionable_conditions.append(
                    questionable_df['MATCH_REASON'].str.contains('‚ö†Ô∏è|QUESTIONABLE|FALSE POSITIVE', case=False, na=False)
                )
            
            # 4. Short pattern values (likely false positives)
            if 'PATTERN_VALUE' in questionable_df.columns:
                questionable_conditions.append(
                    (questionable_df['PATTERN_TYPE'] == 'CONTAINS') & 
                    (questionable_df['PATTERN_VALUE'].str.len() <= 3)
                )
            
            # 5. Domain mismatch indicators (property/actuarial ‚Üí insurance)
            questionable_conditions.append(
                (questionable_df['TABLE_NAME'].str.contains('PROPERTY|ACTUARIAL|HEATING|BUILDING', case=False, na=False)) &
                (questionable_df['MATCHED_DOMAIN'].isin(['Claims', 'Policy', 'Coverage/Rider']))
            )
            
            # Combine all conditions (OR logic - any condition triggers questionable flag)
            if questionable_conditions:
                questionable_mask = questionable_conditions[0]
                for condition in questionable_conditions[1:]:
                    questionable_mask = questionable_mask | condition
                
                questionable_matches = questionable_df[questionable_mask].copy()
            else:
                questionable_matches = pd.DataFrame()
            
            # Display questionable matches
            if len(questionable_matches) > 0:
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.warning(f"‚ö†Ô∏è Found **{len(questionable_matches)}** questionable matches that may be false positives")
                with col2:
                    if st.button("üóëÔ∏è Delete All Questionable", type="secondary"):
                        try:
                            # Delete questionable matches from database
                            scan_ids = questionable_matches['SCAN_ID'].tolist()
                            scan_ids_str = ','.join([str(x) for x in scan_ids])
                            
                            delete_query = f"""
                            DELETE FROM CDE_SCAN_RESULTS
                            WHERE SCAN_ID IN ({scan_ids_str})
                            """
                            session.sql(delete_query).collect()
                            st.success(f"‚úÖ Deleted {len(questionable_matches)} questionable matches")
                            st.rerun()
                        except Exception as e:
                            st.error(f"Error deleting: {str(e)}")
                
                # Show questionable matches in expandable section
                with st.expander(f"üëÅÔ∏è View {len(questionable_matches)} Questionable Matches", expanded=True):
                    for idx, row in questionable_matches.head(50).iterrows():
                        # Determine why it's questionable
                        reasons = []
                        if 'PATTERN_VALUE' in row and str(row['PATTERN_VALUE']) in ['TYPE', 'DATE', 'RATE', 'CODE', 'NAME', 'NUMBER', 'STATUS', 'VALUE', 'AMOUNT', 'ID', 'AGE']:
                            reasons.append(f"Generic pattern: '{row['PATTERN_VALUE']}'")
                        if 'MATCH_SCORE' in row and row['MATCH_SCORE'] < 70:
                            reasons.append(f"Low score: {row['MATCH_SCORE']:.0f}%")
                        if 'MATCH_REASON' in row and ('‚ö†Ô∏è' in str(row['MATCH_REASON']) or 'QUESTIONABLE' in str(row['MATCH_REASON']).upper()):
                            reasons.append("AI flagged")
                        if 'PATTERN_VALUE' in row and 'PATTERN_TYPE' in row and row['PATTERN_TYPE'] == 'CONTAINS' and len(str(row['PATTERN_VALUE'])) <= 3:
                            reasons.append(f"Short: '{row['PATTERN_VALUE']}'")
                        if 'TABLE_NAME' in row and any(word in str(row['TABLE_NAME']).upper() for word in ['PROPERTY', 'ACTUARIAL', 'HEATING', 'BUILDING']):
                            reasons.append("Domain mismatch")
                        
                        reason_text = " | ".join(reasons) if reasons else "Multiple indicators"
                        
                        col_a, col_b = st.columns([4, 1])
                        with col_a:
                            st.markdown(f"**‚ö†Ô∏è {row['TABLE_NAME']}.{row['COLUMN_NAME']} ‚Üí {row['MATCHED_ATTRIBUTE_LOGICAL_NAME']}**")
                            st.caption(f"üîç {reason_text}")
                        with col_b:
                            if st.button("üóëÔ∏è", key=f"del_{row['SCAN_ID']}", help="Delete this match"):
                                try:
                                    session.sql(f"DELETE FROM CDE_SCAN_RESULTS WHERE SCAN_ID = {row['SCAN_ID']}").collect()
                                    st.success("‚úÖ")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"‚ùå {str(e)[:50]}")
                    
                    if len(questionable_matches) > 50:
                        st.info(f"Showing first 50 of {len(questionable_matches)} questionable matches")
                
                # Download questionable matches for review
                st.download_button(
                    label="üì• Download Questionable Matches",
                    data=questionable_matches.to_csv(index=False),
                    file_name=f"questionable_matches_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            else:
                st.success("‚úÖ No questionable matches detected! All results look good.")
            
            # Display results
            st.markdown("---")
            st.markdown("### üìã All Scan Results")
            
            if len(filtered_df) > 0:
                for idx, row in filtered_df.head(50).iterrows():
                    method_badge = f"ü§ñ {row.get('MATCH_METHOD', 'Pattern')}" if 'MATCH_METHOD' in row else "üìê Pattern"
                    pii_icon = "üî¥ PII" if row['MATCHED_IS_PII'] == 'Y' else "üü¢ Non-PII"
                    
                    with st.expander(f"{pii_icon} | {method_badge} | {row['DATABASE_NAME']}.{row['SCHEMA_NAME']}.{row['TABLE_NAME']}.{row['COLUMN_NAME']}"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write(f"**üè¢ Domain:** {row['MATCHED_DOMAIN']}")
                            st.write(f"**üè∑Ô∏è Tag:** {row['MATCHED_TAG']}")
                            st.write(f"**üìù Attribute:** {row['MATCHED_ATTRIBUTE_LOGICAL_NAME']}")
                            st.write(f"**üíæ Data Type:** {row['DATA_TYPE']}")
                        
                        with col2:
                            st.write(f"**üéØ Match Method:** {row.get('MATCH_METHOD', 'Pattern')}")
                            st.write(f"**üìä Match Score:** {row['MATCH_SCORE']:.0f}%")
                            st.write(f"**ü§ñ AI Validated:** {row.get('AI_VALIDATED', False)}")
                            st.write(f"**üìÖ Scan Date:** {row['SCAN_DATE']}")
                        
                        st.markdown("**üß† AI-Generated Match Reasoning:**")
                        st.success(row['MATCH_REASON'])
                
                if len(filtered_df) > 50:
                    st.warning(f"Showing first 50 of {len(filtered_df)} results. Use filters to narrow down.")
            
            # Download
            st.markdown("---")
            csv = filtered_df.to_csv(index=False)
            st.download_button(
                label="üì• Download Filtered Results",
                data=csv,
                file_name=f"cde_findings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
            
            # Analysis
            st.markdown("---")
            st.markdown("### üìä Analysis")
            
            tab1, tab2, tab3 = st.tabs(["Domain Breakdown", "Match Methods", "PII Summary"])
            
            with tab1:
                domain_counts = filtered_df.groupby('MATCHED_DOMAIN').size().reset_index(name='Count')
                domain_counts = domain_counts.sort_values('Count', ascending=False)
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.bar_chart(domain_counts.set_index('MATCHED_DOMAIN'))
                with col2:
                    st.dataframe(domain_counts, use_container_width=True)
            
            with tab2:
                if 'MATCH_METHOD' in filtered_df.columns:
                    method_counts = filtered_df.groupby('MATCH_METHOD').size().reset_index(name='Count')
                    st.bar_chart(method_counts.set_index('MATCH_METHOD'))
                else:
                    st.info("Match method data not available")
            
            with tab3:
                pii_summary = filtered_df.groupby(['MATCHED_DOMAIN', 'MATCHED_IS_PII']).size().reset_index(name='Count')
                pii_pivot = pii_summary.pivot(index='MATCHED_DOMAIN', columns='MATCHED_IS_PII', values='Count').fillna(0)
                st.dataframe(pii_pivot, use_container_width=True)
    
    except Exception as e:
        st.error(f"‚ùå Error loading findings: {str(e)}")

# ==================== SCREEN 4: ASK CORTEX AI ====================
elif page == "üí¨ Ask Cortex AI":
    st.markdown('<div class="main-header">üí¨ Ask Cortex AI</div>', unsafe_allow_html=True)
    st.markdown('<span class="ai-badge">ü§ñ NATURAL LANGUAGE Q&A</span>', unsafe_allow_html=True)
    
    st.markdown("""
    Ask questions about your CDE scan results in natural language. Cortex AI will analyze your data and provide insights.
    """)
    
    st.markdown("---")
    
    # Load context
    try:
        df_results = session.sql("SELECT * FROM CDE_SCAN_RESULTS ORDER BY SCAN_DATE DESC LIMIT 1000").to_pandas()
        df_ref = session.table("CDE_REFERENCE").filter(F.col("IS_ACTIVE") == True).to_pandas()
        
        context_summary = f"""
        AVAILABLE DATA:
        - Total CDE Definitions: {len(df_ref)}
        - Total Scan Results: {len(df_results)}
        - Databases Scanned: {df_results['DATABASE_NAME'].nunique() if len(df_results) > 0 else 0}
        - PII Elements Found: {len(df_results[df_results['MATCHED_IS_PII'] == 'Y']) if len(df_results) > 0 else 0}
        - Domains: {', '.join(df_ref['DOMAIN'].unique())}
        """
        
        st.info(context_summary)
        
        st.markdown("---")
        st.markdown("### ü§ñ Ask Your Question")
        
        # Example questions
        with st.expander("üìù Example Questions"):
            st.markdown("""
            - Which tables contain the most PII data?
            - What are the most common CDEs found in my databases?
            - How many Social Security Number fields were detected?
            - Which domains have the highest risk data?
            - Show me all financial CDEs found in the PROD database
            - What compliance tags are associated with PII data?
            """)
        
        user_question = st.text_area(
            "Your Question:",
            placeholder="e.g., Which tables contain Social Security Numbers?",
            height=100
        )
        
        if st.button("ü§ñ Ask Cortex AI", type="primary"):
            if user_question:
                with st.spinner("ü§ñ Cortex AI is thinking..."):
                    # Prepare detailed context
                    if len(df_results) > 0:
                        sample_results = df_results.head(100)[['DATABASE_NAME', 'SCHEMA_NAME', 'TABLE_NAME', 
                                                                'COLUMN_NAME', 'MATCHED_DOMAIN', 'MATCHED_TAG',
                                                                'MATCHED_ATTRIBUTE_LOGICAL_NAME', 'MATCHED_IS_PII']].to_string()
                    else:
                        sample_results = "No scan results available yet."
                    
                    prompt = f"""You are a data governance analyst with access to CDE scan results.
                    
                    CONTEXT:
                    {context_summary}
                    
                    SAMPLE SCAN RESULTS (first 100 records):
                    {sample_results}
                    
                    USER QUESTION: {user_question}
                    
                    Provide a helpful, accurate answer based on the data above. If you need to make assumptions, state them clearly.
                    Be specific with numbers, table names, and column names when possible.
                    Format your response in a clear, structured way.
                    """
                    
                    try:
                        answer = call_cortex(prompt, 'mixtral-8x7b')
                        
                        st.markdown('<div class="success-ai">', unsafe_allow_html=True)
                        st.markdown("### ü§ñ Cortex AI Response:")
                        st.markdown(answer)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                    except Exception as e:
                        st.error(f"Error: {str(e)}")
            else:
                st.warning("Please enter a question")
    
    except Exception as e:
        st.error(f"Error loading data: {str(e)}")

# Footer
st.sidebar.markdown("---")
st.sidebar.markdown("### üìä Statistics")
try:
    ref_count = session.sql("SELECT COUNT(*) as CNT FROM CDE_REFERENCE WHERE IS_ACTIVE = TRUE").collect()[0]['CNT']
    scan_count = session.sql("SELECT COUNT(*) as CNT FROM CDE_SCAN_RESULTS").collect()[0]['CNT']
    st.sidebar.metric("CDE Definitions", ref_count)
    st.sidebar.metric("Scan Results", scan_count)
except:
    pass

st.sidebar.markdown("---")
st.sidebar.caption("ü§ñ Powered by Snowflake Cortex AI")
st.sidebar.caption("Built with ‚ù§Ô∏è for Data Governance")
